{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import datetime\n",
    "from itertools import product\n",
    "from scipy import interpolate ## For other interpolation functions.\n",
    "import time\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.utils\n",
    "\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "\n",
    "import copy\n",
    "\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with gzip.open('merged7.pkl.gz', 'rb') as fd:\n",
    "    data = pickle.load(fd)\n",
    "\n",
    "with gzip.open('cvleak7-10fold.pkl.gz', 'rb') as fd:\n",
    "    cvleak = pickle.load(fd)\n",
    "    \n",
    "data = pd.merge(data, cvleak, on='activity_id', how='left')\n",
    "\n",
    "with gzip.open('dproc7.pkl.gz', 'rb') as fd:\n",
    "    extra = pickle.load(fd)\n",
    "\n",
    "data = pd.merge(data, extra, on='activity_id', how='left')\n",
    "\n",
    "if True: # Wasteful to recompute a constant every time\n",
    "    mindate = pd.Timestamp('2022-07-17 00:00:00')\n",
    "    maxdate = pd.Timestamp('2023-08-31 00:00:00')\n",
    "    minpdate = pd.Timestamp('2020-05-18 00:00:00')\n",
    "else:\n",
    "    mindate = min(data['date'])\n",
    "    maxdate = max(data['date'])\n",
    "    minpdate = min(data['pdate'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gpreds = pickle.load(open('group3d-xgb-preds.pkl', 'rb'))\n",
    "data = pd.merge(data, df_gpreds, on='group_1', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preproc patches\n",
    "\n",
    "# convert adate_gap nan's to -1 for xgb\n",
    "data.adate_gap.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get adate range maybefeature\n",
    "\n",
    "ad = []\n",
    "for g in data.groupby('achar_10'):\n",
    "    ad.append([g[0], g[1].adate_daynum.min(), g[1].adate_daynum.max(), g[1].adate_daynum.max() - g[1].adate_daynum.min(), len(g[1]), g[1].outcome.sum(), g[1].outcome.mean()])\n",
    "\n",
    "df_ad = pd.DataFrame(ad)\n",
    "\n",
    "df_ad.columns = ['achar_10', 'achar_10_adate_min', 'achar_10_adate_max', 'achar_10_adate_range', 'achar_10_sum', 'achar_10_sum_outcome', 'achar_10_outcome_mean']\n",
    "\n",
    "# Set achar_10 == -1 to -1 (fixme?)\n",
    "df_ad.loc[0, ['achar_10_adate_min']] = -1\n",
    "df_ad.loc[0, ['achar_10_adate_range']] += 1\n",
    "\n",
    "df_adr = df_ad[['achar_10', 'achar_10_adate_range', 'achar_10_adate_min', 'achar_10_adate_max']]\n",
    "\n",
    "data = pd.merge(data, df_adr, on='achar_10', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_orig = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "procs = {}\n",
    "procs['gavg_pc_4_eq24'] = []\n",
    "procs['gavg_pc_2_eq0'] = []\n",
    "for g in data.groupby('group_1'):\n",
    "    procs['gavg_pc_2_eq0'].append([g[0], np.mean(g[1]['pchar_2'] == 0)])\n",
    "    procs['gavg_pc_4_eq24'].append([g[0], np.mean(g[1]['pchar_4'] == 24)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gavg_pc_2_eq0': [[1, 1.0],\n",
       "  [2, 0.24210526315789474],\n",
       "  [3, 0.36170212765957449],\n",
       "  [4, 0.20000000000000001],\n",
       "  [5, 0.58396946564885499],\n",
       "  [6, 0.041095890410958902],\n",
       "  [7, 0.5],\n",
       "  [8, 0.12796208530805686],\n",
       "  [9, 0.125],\n",
       "  [10, 1.0],\n",
       "  [11, 0.22222222222222221],\n",
       "  [12, 1.0],\n",
       "  [13, 0.081081081081081086],\n",
       "  [14, 1.0],\n",
       "  [15, 1.0],\n",
       "  [17, 0.11392405063291139],\n",
       "  [18, 0.35950413223140498],\n",
       "  [20, 0.5],\n",
       "  [21, 0.44444444444444442],\n",
       "  [24, 0.23999999999999999],\n",
       "  [25, 0.20689655172413793],\n",
       "  [26, 0.43783783783783786],\n",
       "  [27, 0.72357723577235777],\n",
       "  [28, 0.14035087719298245],\n",
       "  [29, 0.52083333333333337],\n",
       "  [30, 0.092105263157894732],\n",
       "  [31, 0.18248175182481752],\n",
       "  [32, 0.98936170212765961],\n",
       "  [33, 0.066666666666666666],\n",
       "  [34, 0.28770949720670391],\n",
       "  [35, 0.4943820224719101],\n",
       "  [36, 0.10897435897435898],\n",
       "  [37, 0.32643678160919543],\n",
       "  [38, 0.49230769230769234],\n",
       "  [39, 0.51360174102285094],\n",
       "  [40, 0.054545454545454543],\n",
       "  [41, 0.012195121951219513],\n",
       "  [42, 0.012500000000000001],\n",
       "  [44, 0.5957446808510638],\n",
       "  [46, 0.21311475409836064],\n",
       "  [47, 0.59999999999999998],\n",
       "  [48, 0.1391304347826087],\n",
       "  [49, 0.37995594713656389],\n",
       "  [50, 0.4152542372881356],\n",
       "  [52, 0.3902439024390244],\n",
       "  [53, 1.0],\n",
       "  [54, 0.040000000000000001],\n",
       "  [55, 0.11695906432748537],\n",
       "  [57, 1.0],\n",
       "  [58, 0.0],\n",
       "  [59, 0.52380952380952384],\n",
       "  [60, 0.27927927927927926],\n",
       "  [61, 0.17016317016317017],\n",
       "  [62, 0.090196078431372548],\n",
       "  [64, 0.14606741573033707],\n",
       "  [65, 0.48148148148148145],\n",
       "  [66, 0.31793478260869568],\n",
       "  [67, 0.28272251308900526],\n",
       "  [68, 0.27184466019417475],\n",
       "  [69, 0.0090634441087613302],\n",
       "  [70, 0.91549295774647887],\n",
       "  [71, 1.0],\n",
       "  [72, 0.063063063063063057],\n",
       "  [73, 1.0],\n",
       "  [74, 0.045454545454545456],\n",
       "  [75, 1.0],\n",
       "  [76, 0.27586206896551724],\n",
       "  [77, 0.23703703703703705],\n",
       "  [78, 0.33766233766233766],\n",
       "  [79, 0.30346820809248554],\n",
       "  [80, 0.0],\n",
       "  [82, 0.5],\n",
       "  [83, 0.75739644970414199],\n",
       "  [84, 0.019607843137254902],\n",
       "  [85, 1.0],\n",
       "  [86, 1.0],\n",
       "  [87, 1.0],\n",
       "  [88, 0.029530744336569579],\n",
       "  [90, 0.23809523809523808],\n",
       "  [91, 1.0],\n",
       "  [92, 0.25324675324675322],\n",
       "  [93, 0.5423728813559322],\n",
       "  [94, 0.91489361702127658],\n",
       "  [95, 0.0],\n",
       "  [96, 1.0],\n",
       "  [97, 1.0],\n",
       "  [98, 0.0],\n",
       "  [99, 0.66666666666666663],\n",
       "  [100, 0.68000000000000005],\n",
       "  [102, 0.19526627218934911],\n",
       "  [103, 0.12209302325581395],\n",
       "  [104, 0.31974248927038629],\n",
       "  [105, 0.91549295774647887],\n",
       "  [106, 1.0],\n",
       "  [107, 0.20437956204379562],\n",
       "  [108, 1.0],\n",
       "  [109, 0.023498694516971279],\n",
       "  [110, 0.13555992141453832],\n",
       "  [111, 0.10000000000000001],\n",
       "  [112, 1.0],\n",
       "  [113, 1.0],\n",
       "  [114, 0.3364485981308411],\n",
       "  [115, 1.0],\n",
       "  [116, 0.30319148936170215],\n",
       "  [117, 0.82857142857142863],\n",
       "  [118, 0.18181818181818182],\n",
       "  [119, 0.1368421052631579],\n",
       "  [120, 0.40677966101694918],\n",
       "  [121, 0.30769230769230771],\n",
       "  [122, 0.46153846153846156],\n",
       "  [123, 1.0],\n",
       "  [124, 1.0],\n",
       "  [125, 0.22113022113022113],\n",
       "  [126, 1.0],\n",
       "  [127, 0.40354767184035478],\n",
       "  [129, 0.83333333333333337],\n",
       "  [130, 0.039215686274509803],\n",
       "  [131, 0.33510638297872342],\n",
       "  [132, 0.69565217391304346],\n",
       "  [133, 1.0],\n",
       "  [134, 0.0],\n",
       "  [135, 0.79828326180257514],\n",
       "  [136, 0.5],\n",
       "  [139, 1.0],\n",
       "  [140, 0.093333333333333338],\n",
       "  [141, 0.19626168224299065],\n",
       "  [142, 0.35981308411214952],\n",
       "  [143, 1.0],\n",
       "  [144, 0.323943661971831],\n",
       "  [145, 1.0],\n",
       "  [146, 0.35371179039301309],\n",
       "  [147, 0.29032258064516131],\n",
       "  [148, 0.080536912751677847],\n",
       "  [149, 0.95121951219512191],\n",
       "  [150, 0.53846153846153844],\n",
       "  [151, 0.31632653061224492],\n",
       "  [152, 0.20454545454545456],\n",
       "  [153, 0.39047619047619048],\n",
       "  [154, 1.0],\n",
       "  [155, 0.0],\n",
       "  [156, 0.015625],\n",
       "  [157, 0.20000000000000001],\n",
       "  [158, 0.5],\n",
       "  [159, 0.98717948717948723],\n",
       "  [160, 0.22727272727272727],\n",
       "  [161, 0.23963133640552994],\n",
       "  [162, 0.087499999999999994],\n",
       "  [163, 0.25925925925925924],\n",
       "  [165, 0.20370370370370369],\n",
       "  [166, 0.4375],\n",
       "  [167, 0.47848101265822784],\n",
       "  [168, 0.0],\n",
       "  [169, 0.15492957746478872],\n",
       "  [171, 0.0064516129032258064],\n",
       "  [174, 0.46153846153846156],\n",
       "  [175, 1.0],\n",
       "  [176, 0.0],\n",
       "  [177, 0.41207815275310833],\n",
       "  [178, 0.19823788546255505],\n",
       "  [179, 0.0],\n",
       "  [180, 0.25490196078431371],\n",
       "  [182, 1.0],\n",
       "  [183, 0.024096385542168676],\n",
       "  [184, 0.125],\n",
       "  [185, 0.63829787234042556],\n",
       "  [186, 0.052315608919382507],\n",
       "  [187, 0.22222222222222221],\n",
       "  [188, 0.5],\n",
       "  [189, 0.145748987854251],\n",
       "  [190, 0.42720306513409961],\n",
       "  [191, 0.11582381729200653],\n",
       "  [192, 0.0],\n",
       "  [193, 0.0],\n",
       "  [194, 0.5],\n",
       "  [195, 0.008771929824561403],\n",
       "  [196, 0.096774193548387094],\n",
       "  [197, 0.10975609756097561],\n",
       "  [198, 0.0],\n",
       "  [199, 0.77083333333333337],\n",
       "  [200, 0.47058823529411764],\n",
       "  [201, 0.63157894736842102],\n",
       "  [202, 0.5],\n",
       "  [203, 0.050000000000000003],\n",
       "  [204, 0.87096774193548387],\n",
       "  [205, 1.0],\n",
       "  [206, 0.19736842105263158],\n",
       "  [207, 0.46902654867256638],\n",
       "  [208, 0.34513274336283184],\n",
       "  [209, 1.0],\n",
       "  [210, 0.5],\n",
       "  [211, 0.33333333333333331],\n",
       "  [212, 0.48484848484848486],\n",
       "  [213, 0.77192982456140347],\n",
       "  [214, 0.2762237762237762],\n",
       "  [215, 0.32323232323232326],\n",
       "  [216, 0.75144508670520227],\n",
       "  [217, 0.5],\n",
       "  [218, 1.0],\n",
       "  [219, 0.42160278745644597],\n",
       "  [220, 0.20000000000000001],\n",
       "  [221, 0.072463768115942032],\n",
       "  [223, 0.19339622641509435],\n",
       "  [224, 0.24210526315789474],\n",
       "  [225, 0.55882352941176472],\n",
       "  [226, 0.45454545454545453],\n",
       "  [227, 0.59999999999999998],\n",
       "  [228, 0.096774193548387094],\n",
       "  [229, 0.97701149425287359],\n",
       "  [230, 1.0],\n",
       "  [231, 0.28095238095238095],\n",
       "  [232, 0.95161290322580649],\n",
       "  [233, 0.54545454545454541],\n",
       "  [234, 1.0],\n",
       "  [235, 1.0],\n",
       "  [236, 0.0],\n",
       "  [237, 0.0030487804878048782],\n",
       "  [238, 0.57425742574257421],\n",
       "  [239, 0.0],\n",
       "  [240, 1.0],\n",
       "  [241, 0.1111111111111111],\n",
       "  [242, 0.10000000000000001],\n",
       "  [244, 1.0],\n",
       "  [245, 0.17903930131004367],\n",
       "  [246, 0.042142857142857142],\n",
       "  [247, 1.0],\n",
       "  [248, 0.25],\n",
       "  [249, 0.13114754098360656],\n",
       "  [250, 0.0625],\n",
       "  [251, 0.061728395061728392],\n",
       "  [253, 0.0],\n",
       "  [254, 0.0],\n",
       "  [255, 0.97297297297297303],\n",
       "  [256, 0.63034188034188032],\n",
       "  [257, 0.57894736842105265],\n",
       "  [258, 0.1111111111111111],\n",
       "  [259, 0.40000000000000002],\n",
       "  [261, 0.46835443037974683],\n",
       "  [262, 0.77000000000000002],\n",
       "  [263, 0.17409326424870467],\n",
       "  [265, 0.16304347826086957],\n",
       "  [266, 0.17777777777777778],\n",
       "  [267, 0.77884615384615385],\n",
       "  [268, 0.038694074969770252],\n",
       "  [269, 0.57177615571776153],\n",
       "  [270, 0.029702970297029702],\n",
       "  [271, 0.5],\n",
       "  [272, 0.34554973821989526],\n",
       "  [273, 0.071428571428571425],\n",
       "  [275, 0.90322580645161288],\n",
       "  [276, 0.0],\n",
       "  [277, 1.0],\n",
       "  [278, 0.047619047619047616],\n",
       "  [279, 0.72222222222222221],\n",
       "  [280, 0.29411764705882354],\n",
       "  [281, 0.266347687400319],\n",
       "  [282, 0.66666666666666663],\n",
       "  [283, 0.55945419103313843],\n",
       "  [284, 1.0],\n",
       "  [285, 1.0],\n",
       "  [286, 0.5757575757575758],\n",
       "  [287, 0.84166666666666667],\n",
       "  [288, 0.17741935483870969],\n",
       "  [289, 0.93814432989690721],\n",
       "  [290, 1.0],\n",
       "  [292, 0.19093851132686085],\n",
       "  [293, 1.0],\n",
       "  [294, 0.5641025641025641],\n",
       "  [295, 0.47422680412371132],\n",
       "  [296, 0.0],\n",
       "  [297, 1.0],\n",
       "  [298, 0.84615384615384615],\n",
       "  [299, 1.0],\n",
       "  [301, 0.58333333333333337],\n",
       "  [302, 0.26194398682042835],\n",
       "  [303, 0.95833333333333337],\n",
       "  [304, 1.0],\n",
       "  [305, 1.0],\n",
       "  [306, 0.056930693069306933],\n",
       "  [307, 0.0],\n",
       "  [308, 1.0],\n",
       "  [309, 0.6097560975609756],\n",
       "  [310, 1.0],\n",
       "  [311, 0.16666666666666666],\n",
       "  [312, 1.0],\n",
       "  [313, 1.0],\n",
       "  [314, 0.72072072072072069],\n",
       "  [315, 0.0],\n",
       "  [317, 0.86538461538461542],\n",
       "  [318, 1.0],\n",
       "  [319, 0.39086294416243655],\n",
       "  [320, 0.43010752688172044],\n",
       "  [321, 0.29447236180904524],\n",
       "  [322, 1.0],\n",
       "  [323, 0.40740740740740738],\n",
       "  [324, 0.030927835051546393],\n",
       "  [325, 0.67816091954022983],\n",
       "  [326, 1.0],\n",
       "  [327, 1.0],\n",
       "  [329, 0.2608695652173913],\n",
       "  [330, 0.20000000000000001],\n",
       "  [334, 0.88888888888888884],\n",
       "  [335, 0.11079136690647481],\n",
       "  [337, 0.96153846153846156],\n",
       "  [338, 0.010819165378670788],\n",
       "  [339, 0.5714285714285714],\n",
       "  [340, 1.0],\n",
       "  [341, 1.0],\n",
       "  [342, 0.0],\n",
       "  [343, 0.35714285714285715],\n",
       "  [345, 0.54545454545454541],\n",
       "  [346, 0.66304347826086951],\n",
       "  [347, 0.6428571428571429],\n",
       "  [348, 0.5],\n",
       "  [349, 0.022988505747126436],\n",
       "  [350, 0.76923076923076927],\n",
       "  [351, 0.35159817351598172],\n",
       "  [352, 0.59999999999999998],\n",
       "  [353, 0.055555555555555552],\n",
       "  [355, 0.53383458646616544],\n",
       "  [356, 0.071428571428571425],\n",
       "  [358, 0.0],\n",
       "  [359, 1.0],\n",
       "  [360, 0.20833333333333334],\n",
       "  [361, 0.49197860962566847],\n",
       "  [362, 0.26666666666666666],\n",
       "  [363, 1.0],\n",
       "  [365, 0.41509433962264153],\n",
       "  [366, 0.76146788990825687],\n",
       "  [367, 0.36752136752136755],\n",
       "  [368, 0.67567567567567566],\n",
       "  [369, 0.044444444444444446],\n",
       "  [370, 0.5],\n",
       "  [371, 1.0],\n",
       "  [372, 0.23076923076923078],\n",
       "  [373, 1.0],\n",
       "  [374, 0.0],\n",
       "  [375, 0.40000000000000002],\n",
       "  [376, 0.77777777777777779],\n",
       "  [377, 0.48275862068965519],\n",
       "  [378, 0.92500000000000004],\n",
       "  [380, 0.0],\n",
       "  [381, 0.5],\n",
       "  [382, 0.72222222222222221],\n",
       "  [383, 0.34951456310679613],\n",
       "  [384, 0.42962962962962964],\n",
       "  [385, 0.5],\n",
       "  [386, 0.23577235772357724],\n",
       "  [387, 0.03292181069958848],\n",
       "  [388, 1.0],\n",
       "  [389, 0.3493975903614458],\n",
       "  [391, 0.97499999999999998],\n",
       "  [392, 0.11196911196911197],\n",
       "  [393, 0.0],\n",
       "  [394, 0.5],\n",
       "  [395, 0.14634146341463414],\n",
       "  [396, 0.77777777777777779],\n",
       "  [397, 0.064516129032258063],\n",
       "  [398, 0.16666666666666666],\n",
       "  [399, 0.47692307692307695],\n",
       "  [401, 0.20512820512820512],\n",
       "  [402, 1.0],\n",
       "  [403, 1.0],\n",
       "  [404, 0.29198966408268734],\n",
       "  [405, 0.16666666666666666],\n",
       "  [406, 0.20000000000000001],\n",
       "  [407, 0.57432432432432434],\n",
       "  [408, 0.063829787234042548],\n",
       "  [409, 0.26595744680851063],\n",
       "  [410, 0.31596091205211724],\n",
       "  [411, 0.37669376693766937],\n",
       "  [412, 0.0082987551867219917],\n",
       "  [413, 0.78456591639871387],\n",
       "  [414, 0.16225749559082892],\n",
       "  [415, 1.0],\n",
       "  [416, 0.25],\n",
       "  [417, 0.037037037037037035],\n",
       "  [418, 0.081016949152542372],\n",
       "  [421, 1.0],\n",
       "  [422, 0.57894736842105265],\n",
       "  [423, 0.47820163487738421],\n",
       "  [424, 0.29999999999999999],\n",
       "  [425, 0.33333333333333331],\n",
       "  [426, 0.216],\n",
       "  [427, 0.8571428571428571],\n",
       "  [428, 0.37313432835820898],\n",
       "  [429, 0.82608695652173914],\n",
       "  [430, 0.90625],\n",
       "  [431, 0.875],\n",
       "  [432, 0.36363636363636365],\n",
       "  [433, 0.26415094339622641],\n",
       "  [434, 0.27668539325842695],\n",
       "  [435, 0.52173913043478259],\n",
       "  [436, 1.0],\n",
       "  [439, 0.074999999999999997],\n",
       "  [440, 0.035714285714285712],\n",
       "  [441, 0.41201716738197425],\n",
       "  [443, 0.063116370808678504],\n",
       "  [444, 0.64179104477611937],\n",
       "  [445, 0.17391304347826086],\n",
       "  [446, 0.5],\n",
       "  [448, 0.77000000000000002],\n",
       "  [449, 1.0],\n",
       "  [450, 0.014415156507413509],\n",
       "  [451, 0.2857142857142857],\n",
       "  [452, 0.51071428571428568],\n",
       "  [453, 0.66666666666666663],\n",
       "  [454, 1.0],\n",
       "  [455, 0.5],\n",
       "  [456, 0.5625],\n",
       "  [457, 0.375],\n",
       "  [458, 0.099406528189910984],\n",
       "  [459, 0.23636363636363636],\n",
       "  [461, 1.0],\n",
       "  [462, 0.055555555555555552],\n",
       "  [463, 0.47441860465116281],\n",
       "  [464, 0.25646551724137934],\n",
       "  [465, 0.44444444444444442],\n",
       "  [467, 0.96052631578947367],\n",
       "  [468, 0.51741293532338306],\n",
       "  [469, 1.0],\n",
       "  [470, 0.017241379310344827],\n",
       "  [471, 0.16901408450704225],\n",
       "  [472, 0.0],\n",
       "  [473, 0.27179487179487177],\n",
       "  [474, 0.5],\n",
       "  [475, 0.63888888888888884],\n",
       "  [476, 0.084337349397590355],\n",
       "  [477, 0.063063063063063057],\n",
       "  [478, 0.75],\n",
       "  [479, 0.40000000000000002],\n",
       "  [480, 1.0],\n",
       "  [481, 0.0],\n",
       "  [482, 0.71641791044776115],\n",
       "  [483, 0.59999999999999998],\n",
       "  [486, 0.26225490196078433],\n",
       "  [487, 0.50943396226415094],\n",
       "  [488, 0.041666666666666664],\n",
       "  [489, 0.25],\n",
       "  [490, 1.0],\n",
       "  [491, 0.29041095890410956],\n",
       "  [492, 0.14534883720930233],\n",
       "  [493, 0.40740740740740738],\n",
       "  [494, 1.0],\n",
       "  [495, 0.115],\n",
       "  [496, 0.33333333333333331],\n",
       "  [497, 0.89655172413793105],\n",
       "  [498, 0.086124401913875603],\n",
       "  [500, 0.34883720930232559],\n",
       "  [501, 1.0],\n",
       "  [502, 0.29166666666666669],\n",
       "  [503, 0.09375],\n",
       "  [504, 0.0029556650246305421],\n",
       "  [505, 0.15668202764976957],\n",
       "  [506, 0.75],\n",
       "  [507, 0.19434628975265017],\n",
       "  [508, 0.70873786407766992],\n",
       "  [509, 1.0],\n",
       "  [510, 0.019138755980861243],\n",
       "  [513, 0.34285714285714286],\n",
       "  [514, 0.33333333333333331],\n",
       "  [515, 1.0],\n",
       "  [516, 0.053164556962025315],\n",
       "  [517, 0.035087719298245612],\n",
       "  [519, 0.044444444444444446],\n",
       "  [520, 0.83050847457627119],\n",
       "  [521, 0.0070175438596491229],\n",
       "  [522, 0.0021929824561403508],\n",
       "  [524, 0.83606557377049184],\n",
       "  [525, 1.0],\n",
       "  [526, 1.0],\n",
       "  [527, 0.044444444444444446],\n",
       "  [529, 1.0],\n",
       "  [530, 0.5],\n",
       "  [531, 0.31132075471698112],\n",
       "  [532, 0.40909090909090912],\n",
       "  [533, 0.092307692307692313],\n",
       "  [534, 1.0],\n",
       "  [535, 0.0],\n",
       "  [536, 0.33333333333333331],\n",
       "  [537, 0.076923076923076927],\n",
       "  [538, 0.5],\n",
       "  [539, 0.5],\n",
       "  [540, 1.0],\n",
       "  [541, 0.2318840579710145],\n",
       "  [542, 0.22222222222222221],\n",
       "  [543, 0.12878787878787878],\n",
       "  [544, 0.32967032967032966],\n",
       "  [545, 0.33668341708542715],\n",
       "  [546, 0.75609756097560976],\n",
       "  [547, 1.0],\n",
       "  [548, 0.75438596491228072],\n",
       "  [549, 1.0],\n",
       "  [550, 0.0],\n",
       "  [551, 0.0],\n",
       "  [552, 0.67031249999999998],\n",
       "  [553, 0.25],\n",
       "  [554, 0.5],\n",
       "  [555, 0.71604938271604934],\n",
       "  [557, 0.42038216560509556],\n",
       "  [558, 0.79047619047619044],\n",
       "  [559, 0.029702970297029702],\n",
       "  [560, 0.0],\n",
       "  [561, 1.0],\n",
       "  [562, 0.2857142857142857],\n",
       "  [563, 0.56000000000000005],\n",
       "  [564, 0.33333333333333331],\n",
       "  [565, 0.38878386893509764],\n",
       "  [566, 0.035294117647058823],\n",
       "  [567, 0.64864864864864868],\n",
       "  [569, 1.0],\n",
       "  [570, 0.11235955056179775],\n",
       "  [571, 1.0],\n",
       "  [572, 0.27777777777777779],\n",
       "  [573, 0.88888888888888884],\n",
       "  [574, 0.3346456692913386],\n",
       "  [575, 0.5],\n",
       "  [576, 0.62845849802371545],\n",
       "  [577, 0.051351351351351354],\n",
       "  [578, 0.46721311475409838],\n",
       "  [579, 0.55913978494623651],\n",
       "  [580, 0.44413407821229051],\n",
       "  [581, 0.0],\n",
       "  [582, 0.49019607843137253],\n",
       "  [584, 0.050434782608695654],\n",
       "  [585, 0.4906621392190153],\n",
       "  [587, 0.48837209302325579],\n",
       "  [588, 0.32000000000000001],\n",
       "  [589, 0.36363636363636365],\n",
       "  [590, 0.44690265486725661],\n",
       "  [592, 0.97727272727272729],\n",
       "  [593, 0.46263345195729538],\n",
       "  [594, 0.87179487179487181],\n",
       "  [595, 1.0],\n",
       "  [597, 0.061538461538461542],\n",
       "  [598, 1.0],\n",
       "  [599, 0.25],\n",
       "  [600, 0.45955882352941174],\n",
       "  [601, 0.33583489681050654],\n",
       "  [603, 0.26315789473684209],\n",
       "  [604, 0.59663865546218486],\n",
       "  [605, 0.5],\n",
       "  [606, 0.1111111111111111],\n",
       "  [607, 0.0],\n",
       "  [609, 0.19298245614035087],\n",
       "  [611, 0.40845070422535212],\n",
       "  [612, 0.49767441860465117],\n",
       "  [613, 0.625],\n",
       "  [614, 0.5],\n",
       "  [615, 0.084745762711864403],\n",
       "  [617, 0.0449438202247191],\n",
       "  [618, 0.0],\n",
       "  [620, 0.8125],\n",
       "  [621, 1.0],\n",
       "  [622, 0.043859649122807015],\n",
       "  [623, 0.53333333333333333],\n",
       "  [624, 0.0],\n",
       "  [625, 0.342443729903537],\n",
       "  [626, 0.97959183673469385],\n",
       "  [627, 0.086021505376344093],\n",
       "  [628, 0.16949152542372881],\n",
       "  [629, 0.25],\n",
       "  [630, 0.41682974559686886],\n",
       "  [631, 1.0],\n",
       "  [632, 0.50943396226415094],\n",
       "  [633, 0.5],\n",
       "  [635, 1.0],\n",
       "  [636, 1.0],\n",
       "  [637, 0.016528925619834711],\n",
       "  [638, 0.4375],\n",
       "  [639, 0.12987012987012986],\n",
       "  [640, 0.070175438596491224],\n",
       "  [641, 0.38461538461538464],\n",
       "  [642, 0.29166666666666669],\n",
       "  [643, 0.059196617336152217],\n",
       "  [644, 0.77777777777777779],\n",
       "  [646, 0.32520325203252032],\n",
       "  [647, 0.51000000000000001],\n",
       "  [648, 0.66666666666666663],\n",
       "  [649, 0.056451612903225805],\n",
       "  [651, 0.86734693877551017],\n",
       "  [652, 0.29629629629629628],\n",
       "  [653, 0.16],\n",
       "  [654, 0.0],\n",
       "  [655, 0.5],\n",
       "  [656, 0.35406698564593303],\n",
       "  [657, 1.0],\n",
       "  [658, 0.35374149659863946],\n",
       "  [659, 0.043165467625899283],\n",
       "  [661, 0.47457627118644069],\n",
       "  [662, 1.0],\n",
       "  [665, 0.34090909090909088],\n",
       "  [666, 0.44221105527638194],\n",
       "  [667, 0.0011634377054985077],\n",
       "  [668, 0.36170212765957449],\n",
       "  [669, 0.15789473684210525],\n",
       "  [670, 0.16666666666666666],\n",
       "  [671, 0.31950207468879666],\n",
       "  [672, 0.16666666666666666],\n",
       "  [673, 0.58823529411764708],\n",
       "  [674, 0.24713958810068651],\n",
       "  [675, 0.35256410256410259],\n",
       "  [676, 0.18604651162790697],\n",
       "  [677, 0.41935483870967744],\n",
       "  [678, 0.921875],\n",
       "  [679, 0.58381502890173409],\n",
       "  [680, 0.069767441860465115],\n",
       "  [681, 0.73255813953488369],\n",
       "  [682, 0.0],\n",
       "  [683, 1.0],\n",
       "  [684, 0.47663551401869159],\n",
       "  [685, 1.0],\n",
       "  [686, 0.0],\n",
       "  [687, 0.44959128065395093],\n",
       "  [688, 0.023809523809523808],\n",
       "  [689, 0.71875],\n",
       "  [691, 0.5],\n",
       "  [694, 0.49206349206349204],\n",
       "  [695, 0.47499999999999998],\n",
       "  [696, 0.067073170731707321],\n",
       "  [697, 0.5],\n",
       "  [698, 0.54320987654320985],\n",
       "  [699, 0.88571428571428568],\n",
       "  [700, 0.74277456647398843],\n",
       "  [701, 0.66666666666666663],\n",
       "  [702, 1.0],\n",
       "  [703, 0.10204081632653061],\n",
       "  [704, 0.75],\n",
       "  [705, 0.49805447470817121],\n",
       "  [706, 0.013333333333333334],\n",
       "  [707, 0.29342105263157897],\n",
       "  [708, 0.30252100840336132],\n",
       "  [709, 0.62184873949579833],\n",
       "  [710, 1.0],\n",
       "  [711, 0.068965517241379309],\n",
       "  [712, 0.67420814479638014],\n",
       "  [714, 0.5625],\n",
       "  [715, 0.7142857142857143],\n",
       "  [716, 1.0],\n",
       "  [717, 0.15686274509803921],\n",
       "  [718, 0.0],\n",
       "  [719, 0.053977272727272728],\n",
       "  [720, 0.5356037151702786],\n",
       "  [721, 0.70238095238095233],\n",
       "  [722, 0.30263157894736842],\n",
       "  [723, 0.35483870967741937],\n",
       "  [725, 0.34979423868312759],\n",
       "  [726, 0.4943502824858757],\n",
       "  [727, 0.16666666666666666],\n",
       "  [730, 1.0],\n",
       "  [731, 0.18327974276527331],\n",
       "  [732, 1.0],\n",
       "  [733, 0.071082390953150248],\n",
       "  [734, 0.11851851851851852],\n",
       "  [735, 0.13043478260869565],\n",
       "  [736, 0.33557046979865773],\n",
       "  [737, 1.0],\n",
       "  [738, 0.0],\n",
       "  [739, 0.53333333333333333],\n",
       "  [740, 0.52083333333333337],\n",
       "  [741, 0.0],\n",
       "  [742, 0.81720430107526887],\n",
       "  [743, 0.25],\n",
       "  [744, 0.14942528735632185],\n",
       "  [745, 1.0],\n",
       "  [746, 0.051724137931034482],\n",
       "  [747, 0.0],\n",
       "  [749, 1.0],\n",
       "  [750, 0.24334600760456274],\n",
       "  [751, 1.0],\n",
       "  [752, 0.003663003663003663],\n",
       "  [753, 0.087999999999999995],\n",
       "  [754, 0.18478260869565216],\n",
       "  [756, 0.0],\n",
       "  [757, 0.0047846889952153108],\n",
       "  [758, 0.90196078431372551],\n",
       "  [759, 0.12280701754385964],\n",
       "  [760, 0.5053003533568905],\n",
       "  [761, 0.58333333333333337],\n",
       "  [762, 1.0],\n",
       "  [763, 0.31578947368421051],\n",
       "  [764, 0.43518518518518517],\n",
       "  [765, 0.35294117647058826],\n",
       "  [767, 0.15625],\n",
       "  [768, 0.0067264573991031393],\n",
       "  [769, 0.055555555555555552],\n",
       "  [771, 1.0],\n",
       "  [773, 0.35714285714285715],\n",
       "  [774, 0.32608695652173914],\n",
       "  [775, 0.5],\n",
       "  [776, 1.0],\n",
       "  [777, 0.9543568464730291],\n",
       "  [778, 0.17676767676767677],\n",
       "  [779, 0.21365638766519823],\n",
       "  [780, 0.52601156069364163],\n",
       "  [781, 0.2247191011235955],\n",
       "  [782, 0.94059405940594054],\n",
       "  [783, 0.0],\n",
       "  [784, 1.0],\n",
       "  [785, 0.32142857142857145],\n",
       "  [786, 1.0],\n",
       "  [788, 0.76000000000000001],\n",
       "  [789, 0.0],\n",
       "  [790, 0.9642857142857143],\n",
       "  [791, 0.3888888888888889],\n",
       "  [792, 0.50617283950617287],\n",
       "  [793, 0.0945945945945946],\n",
       "  [794, 0.5252525252525253],\n",
       "  [795, 0.0070422535211267607],\n",
       "  [796, 0.59649122807017541],\n",
       "  [799, 0.47058823529411764],\n",
       "  [800, 0.0],\n",
       "  [801, 0.31844946025515208],\n",
       "  [802, 0.24161073825503357],\n",
       "  [803, 0.36538461538461536],\n",
       "  [804, 0.081081081081081086],\n",
       "  [805, 0.19943422913719944],\n",
       "  [808, 0.10000000000000001],\n",
       "  [810, 0.66666666666666663],\n",
       "  [811, 0.13245033112582782],\n",
       "  [812, 0.29166666666666669],\n",
       "  [813, 0.53183520599250933],\n",
       "  [814, 0.15463917525773196],\n",
       "  [815, 1.0],\n",
       "  [816, 0.56521739130434778],\n",
       "  [817, 0.033707865168539325],\n",
       "  [818, 0.15957446808510639],\n",
       "  [819, 0.5],\n",
       "  [820, 0.88095238095238093],\n",
       "  [821, 0.35714285714285715],\n",
       "  [823, 0.42424242424242425],\n",
       "  [824, 0.09388335704125178],\n",
       "  [826, 0.89473684210526316],\n",
       "  [829, 0.34615384615384615],\n",
       "  [830, 0.019230769230769232],\n",
       "  [832, 0.55855855855855852],\n",
       "  [833, 0.25531914893617019],\n",
       "  [836, 0.063492063492063489],\n",
       "  [837, 0.0],\n",
       "  [838, 0.18390804597701149],\n",
       "  [839, 0.9445910290237467],\n",
       "  [840, 1.0],\n",
       "  [842, 0.065217391304347824],\n",
       "  [843, 0.5],\n",
       "  [844, 0.01636904761904762],\n",
       "  [845, 0.5625],\n",
       "  [846, 0.36607142857142855],\n",
       "  [847, 0.50724637681159424],\n",
       "  [848, 0.10000000000000001],\n",
       "  [849, 1.0],\n",
       "  [850, 0.23711340206185566],\n",
       "  [851, 0.5],\n",
       "  [852, 0.22222222222222221],\n",
       "  [853, 0.91666666666666663],\n",
       "  [854, 0.8666666666666667],\n",
       "  [855, 0.41971830985915493],\n",
       "  [856, 0.32500000000000001],\n",
       "  [857, 0.055555555555555552],\n",
       "  [858, 0.16129032258064516],\n",
       "  [859, 1.0],\n",
       "  [860, 1.0],\n",
       "  [861, 0.42513368983957217],\n",
       "  [862, 1.0],\n",
       "  [863, 0.5],\n",
       "  [864, 0.044776119402985072],\n",
       "  [865, 0.21052631578947367],\n",
       "  [866, 0.66666666666666663],\n",
       "  [867, 0.25],\n",
       "  [868, 0.33333333333333331],\n",
       "  [869, 0.055900621118012424],\n",
       "  [870, 0.26785714285714285],\n",
       "  [871, 0.43795620437956206],\n",
       "  [872, 0.91428571428571426],\n",
       "  [873, 0.075630252100840331],\n",
       "  [874, 1.0],\n",
       "  [875, 0.73684210526315785],\n",
       "  [876, 0.375],\n",
       "  [877, 0.083333333333333329],\n",
       "  [878, 0.59999999999999998],\n",
       "  [879, 0.50632911392405067],\n",
       "  [880, 0.24166666666666667],\n",
       "  [881, 0.6333333333333333],\n",
       "  [882, 0.079646017699115043],\n",
       "  [883, 0.5],\n",
       "  [884, 0.5],\n",
       "  [885, 0.47154471544715448],\n",
       "  [886, 0.0],\n",
       "  [887, 0.84183673469387754],\n",
       "  [889, 1.0],\n",
       "  [890, 0.016393442622950821],\n",
       "  [891, 0.066666666666666666],\n",
       "  [892, 1.0],\n",
       "  [893, 0.0],\n",
       "  [894, 0.47080291970802918],\n",
       "  [897, 0.39344262295081966],\n",
       "  [898, 0.067796610169491525],\n",
       "  [899, 1.0],\n",
       "  [900, 0.5],\n",
       "  [902, 0.01020408163265306],\n",
       "  [903, 1.0],\n",
       "  [904, 0.36666666666666664],\n",
       "  [905, 0.57499999999999996],\n",
       "  [908, 0.09815950920245399],\n",
       "  [909, 1.0],\n",
       "  [910, 0.090909090909090912],\n",
       "  [911, 0.69999999999999996],\n",
       "  [912, 0.10204081632653061],\n",
       "  [913, 0.22023809523809523],\n",
       "  [914, 0.0],\n",
       "  [915, 0.55172413793103448],\n",
       "  [916, 0.066666666666666666],\n",
       "  [918, 1.0],\n",
       "  [919, 0.5161290322580645],\n",
       "  [920, 0.66666666666666663],\n",
       "  [921, 0.82926829268292679],\n",
       "  [922, 0.95604395604395609],\n",
       "  [923, 0.24590163934426229],\n",
       "  [924, 0.45454545454545453],\n",
       "  [925, 1.0],\n",
       "  [926, 0.6428571428571429],\n",
       "  [927, 1.0],\n",
       "  [928, 0.0],\n",
       "  [929, 0.3622641509433962],\n",
       "  [930, 0.5],\n",
       "  [931, 0.18857142857142858],\n",
       "  [932, 0.10169491525423729],\n",
       "  [933, 0.037499999999999999],\n",
       "  [934, 0.83333333333333337],\n",
       "  [937, 0.94117647058823528],\n",
       "  [938, 0.0],\n",
       "  [939, 0.25641025641025639],\n",
       "  [940, 0.49090909090909091],\n",
       "  [941, 0.63636363636363635],\n",
       "  [942, 0.28125],\n",
       "  [943, 0.034690799396681751],\n",
       "  [944, 1.0],\n",
       "  [945, 0.29999999999999999],\n",
       "  [946, 1.0],\n",
       "  [947, 0.84964200477326968],\n",
       "  [948, 1.0],\n",
       "  [949, 1.0],\n",
       "  [951, 0.89473684210526316],\n",
       "  [952, 0.032258064516129031],\n",
       "  [953, 0.2857142857142857],\n",
       "  [954, 1.0],\n",
       "  [955, 1.0],\n",
       "  [956, 0.031299734748010608],\n",
       "  [957, 0.0],\n",
       "  [958, 0.66666666666666663],\n",
       "  [959, 0.0],\n",
       "  [960, 0.8571428571428571],\n",
       "  [961, 0.75],\n",
       "  [962, 0.15277777777777779],\n",
       "  [963, 0.4491315136476427],\n",
       "  [964, 0.035087719298245612],\n",
       "  [965, 0.39430894308943087],\n",
       "  [967, 0.65126050420168069],\n",
       "  [968, 0.5],\n",
       "  [969, 0.0084388185654008432],\n",
       "  [970, 0.53061224489795922],\n",
       "  [971, 0.97368421052631582],\n",
       "  [972, 0.12626262626262627],\n",
       "  [973, 0.076923076923076927],\n",
       "  [974, 0.052631578947368418],\n",
       "  [975, 0.49572649572649574],\n",
       "  [976, 0.5],\n",
       "  [977, 0.16666666666666666],\n",
       "  [978, 1.0],\n",
       "  [979, 0.42424242424242425],\n",
       "  [980, 0.32891832229580575],\n",
       "  [981, 0.36963696369636961],\n",
       "  [982, 0.18181818181818182],\n",
       "  [983, 0.48529411764705882],\n",
       "  [984, 1.0],\n",
       "  [985, 0.083333333333333329],\n",
       "  [988, 0.5],\n",
       "  [989, 0.060810810810810814],\n",
       "  [990, 1.0],\n",
       "  [991, 0.49322493224932251],\n",
       "  [992, 1.0],\n",
       "  [993, 1.0],\n",
       "  [994, 0.020100502512562814],\n",
       "  [996, 0.55882352941176472],\n",
       "  [997, 0.030612244897959183],\n",
       "  [998, 0.95999999999999996],\n",
       "  [999, 0.19277108433734941],\n",
       "  [1000, 0.028089887640449437],\n",
       "  [1001, 0.09330628803245436],\n",
       "  [1002, 1.0],\n",
       "  [1003, 0.10526315789473684],\n",
       "  [1004, 0.0],\n",
       "  [1005, 0.021276595744680851],\n",
       "  [1006, 0.12195121951219512],\n",
       "  [1007, 0.32596685082872928],\n",
       "  [1008, 0.39583333333333331],\n",
       "  [1009, 0.234375],\n",
       "  [1010, 0.4642857142857143],\n",
       "  [1011, 0.35459662288930582],\n",
       "  [1012, 0.125],\n",
       "  [1014, 0.1111111111111111],\n",
       "  [1015, 0.65384615384615385],\n",
       "  [1016, 0.83333333333333337],\n",
       "  [1018, 1.0],\n",
       "  [1019, 0.44155844155844154],\n",
       "  [1020, 0.38461538461538464],\n",
       "  [1021, 0.028880866425992781],\n",
       "  [1022, 0.02],\n",
       "  [1024, 0.10000000000000001],\n",
       "  [1025, 0.16806722689075632],\n",
       "  [1026, 0.21802325581395349],\n",
       "  [1028, 0.19469026548672566],\n",
       "  [1029, 0.33333333333333331],\n",
       "  [1030, 0.5],\n",
       "  [1031, 1.0],\n",
       "  [1032, 0.42857142857142855],\n",
       "  [1033, 0.625],\n",
       "  [1034, 0.0],\n",
       "  [1035, 0.7189189189189189],\n",
       "  [1036, 0.38271604938271603],\n",
       "  [1038, 1.0],\n",
       "  [1039, 0.16831683168316833],\n",
       "  [1040, 0.41666666666666669],\n",
       "  [1041, 0.5],\n",
       "  [1042, 0.61823361823361822],\n",
       "  [1043, 0.0],\n",
       "  [1044, 0.09450038729666925],\n",
       "  [1045, 0.72881355932203384],\n",
       "  [1046, 0.41666666666666669],\n",
       "  [1047, 0.082792207792207792],\n",
       "  [1049, 0.5],\n",
       "  [1050, 0.30246913580246915],\n",
       "  [1051, 1.0],\n",
       "  [1052, 0.40594059405940597],\n",
       "  [1053, 1.0],\n",
       "  [1055, 0.0],\n",
       "  [1056, 0.61111111111111116],\n",
       "  [1058, 0.026143790849673203],\n",
       "  [1060, 0.080000000000000002],\n",
       "  [1061, 1.0],\n",
       "  [1062, 0.096774193548387094],\n",
       "  [1063, 1.0],\n",
       "  [1064, 0.029787234042553193],\n",
       "  [1065, 1.0],\n",
       "  [1066, 0.13242009132420091],\n",
       "  [1067, 0.0],\n",
       "  [1068, 0.29999999999999999],\n",
       "  [1069, 0.40909090909090912],\n",
       "  [1070, 0.44425087108013939],\n",
       "  [1071, 0.51595744680851063],\n",
       "  [1072, 0.33333333333333331],\n",
       "  [1073, 1.0],\n",
       "  [1074, 0.0],\n",
       "  [1076, 0.16666666666666666],\n",
       "  [1077, 0.016393442622950821],\n",
       "  [1079, 0.16842105263157894],\n",
       "  [1080, 0.97802197802197799],\n",
       "  [1081, 0.045454545454545456],\n",
       "  [1082, 0.21212121212121213],\n",
       "  [1083, 0.09375],\n",
       "  [1084, 0.0],\n",
       "  [1085, 0.25862068965517243],\n",
       "  [1086, 1.0],\n",
       "  [1087, 0.54716981132075471],\n",
       "  [1088, 1.0],\n",
       "  [1089, 0.46875],\n",
       "  [1090, 0.18984962406015038],\n",
       "  [1091, 0.0625],\n",
       "  [1092, 0.033653846153846152],\n",
       "  [1093, 0.30864197530864196],\n",
       "  [1094, 0.34188034188034189],\n",
       "  [1095, 0.086206896551724144],\n",
       "  [1096, 0.030303030303030304],\n",
       "  [1097, 1.0],\n",
       "  [1098, 0.0],\n",
       "  [1099, 0.59999999999999998],\n",
       "  [1100, 0.5],\n",
       "  [1101, 0.99607843137254903],\n",
       "  [1102, 0.29411764705882354],\n",
       "  [1103, 0.33057851239669422],\n",
       "  [1104, 0.66666666666666663],\n",
       "  [1105, 0.031315240083507306],\n",
       "  [1106, 1.0],\n",
       "  [1108, 0.75],\n",
       "  [1109, 0.0],\n",
       "  [1110, 0.40000000000000002],\n",
       "  [1111, 0.0],\n",
       "  [1112, 0.5],\n",
       "  [1113, 0.30252100840336132],\n",
       "  [1114, 0.068965517241379309],\n",
       "  [1115, 0.013513513513513514],\n",
       "  [1116, 0.29999999999999999],\n",
       "  [1117, 0.31343283582089554],\n",
       "  [1119, 0.0],\n",
       "  [1120, 0.0],\n",
       "  [1121, 0.98648648648648651],\n",
       "  [1123, 0.0],\n",
       "  [1124, 0.22058823529411764],\n",
       "  [1125, 0.015151515151515152],\n",
       "  [1126, 0.91133004926108374],\n",
       "  [1127, 0.028199566160520606],\n",
       "  [1128, 0.40000000000000002],\n",
       "  ...],\n",
       " 'gavg_pc_4_eq24': [[1, 0.0],\n",
       "  [2, 0.0],\n",
       "  [3, 0.53191489361702127],\n",
       "  [4, 0.14999999999999999],\n",
       "  [5, 0.27480916030534353],\n",
       "  [6, 0.0],\n",
       "  [7, 0.0],\n",
       "  [8, 0.35545023696682465],\n",
       "  [9, 0.58522727272727271],\n",
       "  [10, 0.0],\n",
       "  [11, 0.0],\n",
       "  [12, 0.0],\n",
       "  [13, 0.0],\n",
       "  [14, 0.0],\n",
       "  [15, 0.0],\n",
       "  [17, 0.13502109704641349],\n",
       "  [18, 0.0],\n",
       "  [20, 0.0],\n",
       "  [21, 0.0],\n",
       "  [24, 0.35777777777777775],\n",
       "  [25, 0.7931034482758621],\n",
       "  [26, 0.03783783783783784],\n",
       "  [27, 0.035230352303523033],\n",
       "  [28, 0.35087719298245612],\n",
       "  [29, 0.0],\n",
       "  [30, 0.013157894736842105],\n",
       "  [31, 0.46715328467153283],\n",
       "  [32, 0.0],\n",
       "  [33, 0.8833333333333333],\n",
       "  [34, 0.67318435754189943],\n",
       "  [35, 0.0],\n",
       "  [36, 0.20940170940170941],\n",
       "  [37, 0.54712643678160922],\n",
       "  [38, 0.0],\n",
       "  [39, 0.26659412404787813],\n",
       "  [40, 0.18181818181818182],\n",
       "  [41, 0.61382113821138207],\n",
       "  [42, 0.0],\n",
       "  [44, 0.085106382978723402],\n",
       "  [46, 0.29508196721311475],\n",
       "  [47, 0.40000000000000002],\n",
       "  [48, 0.0086956521739130436],\n",
       "  [49, 0.096916299559471369],\n",
       "  [50, 0.059322033898305086],\n",
       "  [52, 0.26480836236933797],\n",
       "  [53, 0.0],\n",
       "  [54, 0.95999999999999996],\n",
       "  [55, 0.56140350877192979],\n",
       "  [57, 0.0],\n",
       "  [58, 0.42857142857142855],\n",
       "  [59, 0.19047619047619047],\n",
       "  [60, 0.72072072072072069],\n",
       "  [61, 0.0],\n",
       "  [62, 0.062745098039215685],\n",
       "  [64, 0.0],\n",
       "  [65, 0.0],\n",
       "  [66, 0.04619565217391304],\n",
       "  [67, 0.12041884816753927],\n",
       "  [68, 0.48404993065187241],\n",
       "  [69, 0.0090634441087613302],\n",
       "  [70, 0.0],\n",
       "  [71, 0.0],\n",
       "  [72, 0.0],\n",
       "  [73, 0.0],\n",
       "  [74, 0.82954545454545459],\n",
       "  [75, 0.0],\n",
       "  [76, 0.31034482758620691],\n",
       "  [77, 0.70370370370370372],\n",
       "  [78, 0.07792207792207792],\n",
       "  [79, 0.19364161849710981],\n",
       "  [80, 1.0],\n",
       "  [82, 0.0],\n",
       "  [83, 0.0],\n",
       "  [84, 0.21568627450980393],\n",
       "  [85, 0.0],\n",
       "  [86, 0.0],\n",
       "  [87, 0.0],\n",
       "  [88, 0.21237864077669902],\n",
       "  [90, 0.76190476190476186],\n",
       "  [91, 0.0],\n",
       "  [92, 0.14285714285714285],\n",
       "  [93, 0.0],\n",
       "  [94, 0.085106382978723402],\n",
       "  [95, 0.0],\n",
       "  [96, 0.0],\n",
       "  [97, 0.0],\n",
       "  [98, 0.0],\n",
       "  [99, 0.33333333333333331],\n",
       "  [100, 0.0],\n",
       "  [102, 0.1893491124260355],\n",
       "  [103, 0.063953488372093026],\n",
       "  [104, 0.0],\n",
       "  [105, 0.070422535211267609],\n",
       "  [106, 0.0],\n",
       "  [107, 0.076642335766423361],\n",
       "  [108, 0.0],\n",
       "  [109, 0.13577023498694518],\n",
       "  [110, 0.58153241650294696],\n",
       "  [111, 0.0],\n",
       "  [112, 0.0],\n",
       "  [113, 0.0],\n",
       "  [114, 0.18691588785046728],\n",
       "  [115, 0.0],\n",
       "  [116, 0.015957446808510637],\n",
       "  [117, 0.12857142857142856],\n",
       "  [118, 0.0],\n",
       "  [119, 0.18947368421052632],\n",
       "  [120, 0.0],\n",
       "  [121, 0.44755244755244755],\n",
       "  [122, 0.0],\n",
       "  [123, 0.0],\n",
       "  [124, 0.0],\n",
       "  [125, 0.26781326781326781],\n",
       "  [126, 0.0],\n",
       "  [127, 0.015521064301552107],\n",
       "  [129, 0.0],\n",
       "  [130, 0.17647058823529413],\n",
       "  [131, 0.0],\n",
       "  [132, 0.0],\n",
       "  [133, 0.0],\n",
       "  [134, 1.0],\n",
       "  [135, 0.092989985693848351],\n",
       "  [136, 0.5],\n",
       "  [139, 0.0],\n",
       "  [140, 0.013333333333333334],\n",
       "  [141, 0.028037383177570093],\n",
       "  [142, 0.20753161077515117],\n",
       "  [143, 0.0],\n",
       "  [144, 0.0],\n",
       "  [145, 0.0],\n",
       "  [146, 0.51091703056768556],\n",
       "  [147, 0.70967741935483875],\n",
       "  [148, 0.46979865771812079],\n",
       "  [149, 0.0],\n",
       "  [150, 0.0],\n",
       "  [151, 0.01020408163265306],\n",
       "  [152, 0.75757575757575757],\n",
       "  [153, 0.41904761904761906],\n",
       "  [154, 0.0],\n",
       "  [155, 0.0],\n",
       "  [156, 0.88541666666666663],\n",
       "  [157, 0.30555555555555558],\n",
       "  [158, 0.5],\n",
       "  [159, 0.0],\n",
       "  [160, 0.0],\n",
       "  [161, 0.40552995391705071],\n",
       "  [162, 0.0062500000000000003],\n",
       "  [163, 0.078518518518518515],\n",
       "  [165, 0.0],\n",
       "  [166, 0.0],\n",
       "  [167, 0.11139240506329114],\n",
       "  [168, 0.0],\n",
       "  [169, 0.063380281690140844],\n",
       "  [171, 0.78064516129032258],\n",
       "  [174, 0.11538461538461539],\n",
       "  [175, 0.0],\n",
       "  [176, 0.16666666666666666],\n",
       "  [177, 0.55772646536412074],\n",
       "  [178, 0.022026431718061675],\n",
       "  [179, 0.0],\n",
       "  [180, 0.0],\n",
       "  [182, 0.0],\n",
       "  [183, 0.0],\n",
       "  [184, 0.875],\n",
       "  [185, 0.0],\n",
       "  [186, 0.15608919382504288],\n",
       "  [187, 0.0],\n",
       "  [188, 0.0],\n",
       "  [189, 0.17408906882591094],\n",
       "  [190, 0.07662835249042145],\n",
       "  [191, 0.050570962479608482],\n",
       "  [192, 0.0],\n",
       "  [193, 0.0],\n",
       "  [194, 0.5],\n",
       "  [195, 0.47368421052631576],\n",
       "  [196, 0.0],\n",
       "  [197, 0.0],\n",
       "  [198, 0.10266159695817491],\n",
       "  [199, 0.0],\n",
       "  [200, 0.0],\n",
       "  [201, 0.0],\n",
       "  [202, 0.5],\n",
       "  [203, 0.26666666666666666],\n",
       "  [204, 0.0],\n",
       "  [205, 0.0],\n",
       "  [206, 0.59210526315789469],\n",
       "  [207, 0.15929203539823009],\n",
       "  [208, 0.45132743362831856],\n",
       "  [209, 0.0],\n",
       "  [210, 0.5],\n",
       "  [211, 0.61904761904761907],\n",
       "  [212, 0.0],\n",
       "  [213, 0.026315789473684209],\n",
       "  [214, 0.6048951048951049],\n",
       "  [215, 0.33333333333333331],\n",
       "  [216, 0.011560693641618497],\n",
       "  [217, 0.5],\n",
       "  [218, 0.0],\n",
       "  [219, 0.0034843205574912892],\n",
       "  [220, 0.0],\n",
       "  [221, 0.0],\n",
       "  [223, 0.35849056603773582],\n",
       "  [224, 0.052631578947368418],\n",
       "  [225, 0.0],\n",
       "  [226, 0.097402597402597407],\n",
       "  [227, 0.0],\n",
       "  [228, 0.0],\n",
       "  [229, 0.022988505747126436],\n",
       "  [230, 0.0],\n",
       "  [231, 0.71904761904761905],\n",
       "  [232, 0.048387096774193547],\n",
       "  [233, 0.0],\n",
       "  [234, 0.0],\n",
       "  [235, 0.0],\n",
       "  [236, 1.0],\n",
       "  [237, 0.2225609756097561],\n",
       "  [238, 0.029702970297029702],\n",
       "  [239, 1.0],\n",
       "  [240, 0.0],\n",
       "  [241, 0.0],\n",
       "  [242, 0.066666666666666666],\n",
       "  [244, 0.0],\n",
       "  [245, 0.0],\n",
       "  [246, 0.02642857142857143],\n",
       "  [247, 0.0],\n",
       "  [248, 0.0],\n",
       "  [249, 0.0],\n",
       "  [250, 0.0],\n",
       "  [251, 0.049382716049382713],\n",
       "  [253, 0.0],\n",
       "  [254, 0.35294117647058826],\n",
       "  [255, 0.0],\n",
       "  [256, 0.15384615384615385],\n",
       "  [257, 0.0],\n",
       "  [258, 0.0],\n",
       "  [259, 0.59999999999999998],\n",
       "  [261, 0.027848101265822784],\n",
       "  [262, 0.050000000000000003],\n",
       "  [263, 0.091191709844559585],\n",
       "  [265, 0.0],\n",
       "  [266, 0.0],\n",
       "  [267, 0.04807692307692308],\n",
       "  [268, 0.3555018137847642],\n",
       "  [269, 0.39172749391727496],\n",
       "  [270, 0.97029702970297027],\n",
       "  [271, 0.5],\n",
       "  [272, 0.0],\n",
       "  [273, 0.0],\n",
       "  [275, 0.0],\n",
       "  [276, 0.0],\n",
       "  [277, 0.0],\n",
       "  [278, 0.0],\n",
       "  [279, 0.22222222222222221],\n",
       "  [280, 0.0],\n",
       "  [281, 0.065390749601275916],\n",
       "  [282, 0.083333333333333329],\n",
       "  [283, 0.34113060428849901],\n",
       "  [284, 0.0],\n",
       "  [285, 0.0],\n",
       "  [286, 0.41414141414141414],\n",
       "  [287, 0.11666666666666667],\n",
       "  [288, 0.32258064516129031],\n",
       "  [289, 0.061855670103092786],\n",
       "  [290, 0.0],\n",
       "  [292, 0.080906148867313912],\n",
       "  [293, 0.0],\n",
       "  [294, 0.4358974358974359],\n",
       "  [295, 0.0],\n",
       "  [296, 0.0],\n",
       "  [297, 0.0],\n",
       "  [298, 0.0],\n",
       "  [299, 0.0],\n",
       "  [301, 0.0],\n",
       "  [302, 0.40032948929159801],\n",
       "  [303, 0.0],\n",
       "  [304, 0.0],\n",
       "  [305, 0.0],\n",
       "  [306, 0.051980198019801978],\n",
       "  [307, 0.0],\n",
       "  [308, 0.0],\n",
       "  [309, 0.073170731707317069],\n",
       "  [310, 0.0],\n",
       "  [311, 0.66666666666666663],\n",
       "  [312, 0.0],\n",
       "  [313, 0.0],\n",
       "  [314, 0.0],\n",
       "  [315, 0.0],\n",
       "  [317, 0.0],\n",
       "  [318, 0.0],\n",
       "  [319, 0.005076142131979695],\n",
       "  [320, 0.064516129032258063],\n",
       "  [321, 0.034673366834170855],\n",
       "  [322, 0.0],\n",
       "  [323, 0.009876543209876543],\n",
       "  [324, 0.55051546391752582],\n",
       "  [325, 0.0],\n",
       "  [326, 0.0],\n",
       "  [327, 0.0],\n",
       "  [329, 0.086956521739130432],\n",
       "  [330, 0.67142857142857137],\n",
       "  [334, 0.0],\n",
       "  [335, 0.070503597122302156],\n",
       "  [337, 0.0],\n",
       "  [338, 0.55486862442040186],\n",
       "  [339, 0.0],\n",
       "  [340, 0.0],\n",
       "  [341, 0.0],\n",
       "  [342, 0.0],\n",
       "  [343, 0.6428571428571429],\n",
       "  [345, 0.34343434343434343],\n",
       "  [346, 0.0],\n",
       "  [347, 0.35714285714285715],\n",
       "  [348, 0.0],\n",
       "  [349, 0.0],\n",
       "  [350, 0.23076923076923078],\n",
       "  [351, 0.35616438356164382],\n",
       "  [352, 0.0],\n",
       "  [353, 0.0],\n",
       "  [355, 0.0],\n",
       "  [356, 0.7857142857142857],\n",
       "  [358, 0.31034482758620691],\n",
       "  [359, 0.0],\n",
       "  [360, 0.33333333333333331],\n",
       "  [361, 0.0],\n",
       "  [362, 0.0],\n",
       "  [363, 0.0],\n",
       "  [365, 0.35849056603773582],\n",
       "  [366, 0.0],\n",
       "  [367, 0.0085470085470085479],\n",
       "  [368, 0.0],\n",
       "  [369, 0.0],\n",
       "  [370, 0.5],\n",
       "  [371, 0.0],\n",
       "  [372, 0.17948717948717949],\n",
       "  [373, 0.0],\n",
       "  [374, 0.0],\n",
       "  [375, 0.59999999999999998],\n",
       "  [376, 0.0],\n",
       "  [377, 0.0],\n",
       "  [378, 0.0],\n",
       "  [380, 0.0],\n",
       "  [381, 0.5],\n",
       "  [382, 0.0],\n",
       "  [383, 0.0],\n",
       "  [384, 0.0],\n",
       "  [385, 0.0],\n",
       "  [386, 0.43902439024390244],\n",
       "  [387, 0.053497942386831275],\n",
       "  [388, 0.0],\n",
       "  [389, 0.30120481927710846],\n",
       "  [391, 0.0],\n",
       "  [392, 0.35135135135135137],\n",
       "  [393, 0.42424242424242425],\n",
       "  [394, 0.0],\n",
       "  [395, 0.76422764227642281],\n",
       "  [396, 0.0],\n",
       "  [397, 0.045161290322580643],\n",
       "  [398, 0.16666666666666666],\n",
       "  [399, 0.0],\n",
       "  [401, 0.0],\n",
       "  [402, 0.0],\n",
       "  [403, 0.0],\n",
       "  [404, 0.13953488372093023],\n",
       "  [405, 0.071895424836601302],\n",
       "  [406, 0.20000000000000001],\n",
       "  [407, 0.33108108108108109],\n",
       "  [408, 0.0],\n",
       "  [409, 0.32978723404255317],\n",
       "  [410, 0.36482084690553745],\n",
       "  [411, 0.45528455284552843],\n",
       "  [412, 0.0],\n",
       "  [413, 0.045016077170418008],\n",
       "  [414, 0.084656084656084651],\n",
       "  [415, 0.0],\n",
       "  [416, 0.0],\n",
       "  [417, 0.037037037037037035],\n",
       "  [418, 0.83525423728813564],\n",
       "  [421, 0.0],\n",
       "  [422, 0.0],\n",
       "  [423, 0.061307901907356951],\n",
       "  [424, 0.25],\n",
       "  [425, 0.0],\n",
       "  [426, 0.0],\n",
       "  [427, 0.14285714285714285],\n",
       "  [428, 0.0],\n",
       "  [429, 0.17391304347826086],\n",
       "  [430, 0.0],\n",
       "  [431, 0.0],\n",
       "  [432, 0.27272727272727271],\n",
       "  [433, 0.41509433962264153],\n",
       "  [434, 0.2556179775280899],\n",
       "  [435, 0.014492753623188406],\n",
       "  [436, 0.0],\n",
       "  [439, 0.125],\n",
       "  [440, 0.0],\n",
       "  [441, 0.0],\n",
       "  [443, 0.33333333333333331],\n",
       "  [444, 0.2537313432835821],\n",
       "  [445, 0.021739130434782608],\n",
       "  [446, 0.5],\n",
       "  [448, 0.0],\n",
       "  [449, 0.0],\n",
       "  [450, 0.51235584843492588],\n",
       "  [451, 0.2857142857142857],\n",
       "  [452, 0.04642857142857143],\n",
       "  [453, 0.33333333333333331],\n",
       "  [454, 0.0],\n",
       "  [455, 0.45454545454545453],\n",
       "  [456, 0.0],\n",
       "  [457, 0.0],\n",
       "  [458, 0.0],\n",
       "  [459, 0.12727272727272726],\n",
       "  [461, 0.0],\n",
       "  [462, 0.0],\n",
       "  [463, 0.0],\n",
       "  [464, 0.081896551724137928],\n",
       "  [465, 0.0],\n",
       "  [467, 0.0],\n",
       "  [468, 0.0],\n",
       "  [469, 0.0],\n",
       "  [470, 0.0],\n",
       "  [471, 0.0],\n",
       "  [472, 1.0],\n",
       "  [473, 0.55384615384615388],\n",
       "  [474, 0.0],\n",
       "  [475, 0.013888888888888888],\n",
       "  [476, 0.41967871485943775],\n",
       "  [477, 0.47747747747747749],\n",
       "  [478, 0.25],\n",
       "  [479, 0.0],\n",
       "  [480, 0.0],\n",
       "  [481, 0.0],\n",
       "  [482, 0.28358208955223879],\n",
       "  [483, 0.40000000000000002],\n",
       "  [486, 0.41421568627450983],\n",
       "  [487, 0.0],\n",
       "  [488, 0.54166666666666663],\n",
       "  [489, 0.625],\n",
       "  [490, 0.0],\n",
       "  [491, 0.11780821917808219],\n",
       "  [492, 0.0],\n",
       "  [493, 0.20833333333333334],\n",
       "  [494, 0.0],\n",
       "  [495, 0.46000000000000002],\n",
       "  [496, 0.0],\n",
       "  [497, 0.0],\n",
       "  [498, 0.43062200956937802],\n",
       "  [500, 0.60465116279069764],\n",
       "  [501, 0.0],\n",
       "  [502, 0.70833333333333337],\n",
       "  [503, 0.0],\n",
       "  [504, 0.2620689655172414],\n",
       "  [505, 0.08755760368663594],\n",
       "  [506, 0.0],\n",
       "  [507, 0.038869257950530034],\n",
       "  [508, 0.0],\n",
       "  [509, 0.0],\n",
       "  [510, 0.45933014354066987],\n",
       "  [513, 0.65714285714285714],\n",
       "  [514, 0.0],\n",
       "  [515, 0.0],\n",
       "  [516, 0.0],\n",
       "  [517, 0.96491228070175439],\n",
       "  [519, 0.0],\n",
       "  [520, 0.0],\n",
       "  [521, 0.0],\n",
       "  [522, 0.31798245614035087],\n",
       "  [524, 0.0],\n",
       "  [525, 0.0],\n",
       "  [526, 0.0],\n",
       "  [527, 0.0],\n",
       "  [529, 0.0],\n",
       "  [530, 0.5],\n",
       "  [531, 0.65094339622641506],\n",
       "  [532, 0.06363636363636363],\n",
       "  [533, 0.066666666666666666],\n",
       "  [534, 0.0],\n",
       "  [535, 0.0],\n",
       "  [536, 0.1388888888888889],\n",
       "  [537, 0.0],\n",
       "  [538, 0.0],\n",
       "  [539, 0.0],\n",
       "  [540, 0.0],\n",
       "  [541, 0.37318840579710144],\n",
       "  [542, 0.52941176470588236],\n",
       "  [543, 0.0],\n",
       "  [544, 0.01098901098901099],\n",
       "  [545, 0.23618090452261306],\n",
       "  [546, 0.04878048780487805],\n",
       "  [547, 0.0],\n",
       "  [548, 0.24561403508771928],\n",
       "  [549, 0.0],\n",
       "  [550, 0.0],\n",
       "  [551, 0.0],\n",
       "  [552, 0.025000000000000001],\n",
       "  [553, 0.75],\n",
       "  [554, 0.5],\n",
       "  [555, 0.024691358024691357],\n",
       "  [557, 0.0],\n",
       "  [558, 0.16190476190476191],\n",
       "  [559, 0.019801980198019802],\n",
       "  [560, 0.0],\n",
       "  [561, 0.0],\n",
       "  [562, 0.0],\n",
       "  [563, 0.080000000000000002],\n",
       "  [564, 0.29166666666666669],\n",
       "  [565, 0.4675488342785129],\n",
       "  [566, 0.10196078431372549],\n",
       "  [567, 0.027027027027027029],\n",
       "  [569, 0.0],\n",
       "  [570, 0.16629213483146069],\n",
       "  [571, 0.0],\n",
       "  [572, 0.72222222222222221],\n",
       "  [573, 0.1111111111111111],\n",
       "  [574, 0.2015748031496063],\n",
       "  [575, 0.5],\n",
       "  [576, 0.051383399209486168],\n",
       "  [577, 0.68648648648648647],\n",
       "  [578, 0.0],\n",
       "  [579, 0.053763440860215055],\n",
       "  [580, 0.46927374301675978],\n",
       "  [581, 1.0],\n",
       "  [582, 0.0],\n",
       "  [584, 0.010434782608695653],\n",
       "  [585, 0.11205432937181664],\n",
       "  [587, 0.0],\n",
       "  [588, 0.0],\n",
       "  [589, 0.27272727272727271],\n",
       "  [590, 0.54424778761061943],\n",
       "  [592, 0.0],\n",
       "  [593, 0.15658362989323843],\n",
       "  [594, 0.12820512820512819],\n",
       "  [595, 0.0],\n",
       "  [597, 0.061538461538461542],\n",
       "  [598, 0.0],\n",
       "  [599, 0.4375],\n",
       "  [600, 0.0],\n",
       "  [601, 0.0],\n",
       "  [603, 0.0],\n",
       "  [604, 0.025210084033613446],\n",
       "  [605, 0.5],\n",
       "  [606, 0.0],\n",
       "  [607, 0.0],\n",
       "  [609, 0.0],\n",
       "  [611, 0.0],\n",
       "  [612, 0.0],\n",
       "  [613, 0.0],\n",
       "  [614, 0.5],\n",
       "  [615, 0.84745762711864403],\n",
       "  [617, 0.48314606741573035],\n",
       "  [618, 1.0],\n",
       "  [620, 0.012500000000000001],\n",
       "  [621, 0.0],\n",
       "  [622, 0.28289473684210525],\n",
       "  [623, 0.0],\n",
       "  [624, 0.0],\n",
       "  [625, 0.0],\n",
       "  [626, 0.0],\n",
       "  [627, 0.45161290322580644],\n",
       "  [628, 0.0084745762711864406],\n",
       "  [629, 0.375],\n",
       "  [630, 0.080234833659491189],\n",
       "  [631, 0.0],\n",
       "  [632, 0.0],\n",
       "  [633, 0.0],\n",
       "  [635, 0.0],\n",
       "  [636, 0.0],\n",
       "  [637, 0.0082644628099173556],\n",
       "  [638, 0.0],\n",
       "  [639, 0.0],\n",
       "  [640, 0.24561403508771928],\n",
       "  [641, 0.0],\n",
       "  [642, 0.0],\n",
       "  [643, 0.45243128964059198],\n",
       "  [644, 0.22222222222222221],\n",
       "  [646, 0.17073170731707318],\n",
       "  [647, 0.28000000000000003],\n",
       "  [648, 0.33333333333333331],\n",
       "  [649, 0.60944700460829493],\n",
       "  [651, 0.0],\n",
       "  [652, 0.66666666666666663],\n",
       "  [653, 0.080000000000000002],\n",
       "  [654, 0.0],\n",
       "  [655, 0.0],\n",
       "  [656, 0.42344497607655501],\n",
       "  [657, 0.0],\n",
       "  [658, 0.0],\n",
       "  [659, 0.23021582733812951],\n",
       "  [661, 0.3559322033898305],\n",
       "  [662, 0.0],\n",
       "  [665, 0.0],\n",
       "  [666, 0.085427135678391955],\n",
       "  [667, 0.3036572411351105],\n",
       "  [668, 0.10638297872340426],\n",
       "  [669, 0.21052631578947367],\n",
       "  [670, 0.0],\n",
       "  [671, 0.12863070539419086],\n",
       "  [672, 0.22222222222222221],\n",
       "  [673, 0.012605042016806723],\n",
       "  [674, 0.34096109839816935],\n",
       "  [675, 0.0],\n",
       "  [676, 0.81395348837209303],\n",
       "  [677, 0.0],\n",
       "  [678, 0.046875],\n",
       "  [679, 0.0],\n",
       "  [680, 0.0],\n",
       "  [681, 0.0],\n",
       "  [682, 0.83333333333333337],\n",
       "  [683, 0.0],\n",
       "  [684, 0.0],\n",
       "  [685, 0.0],\n",
       "  [686, 0.20833333333333334],\n",
       "  [687, 0.0],\n",
       "  [688, 0.0],\n",
       "  [689, 0.0],\n",
       "  [691, 0.0],\n",
       "  [694, 0.031746031746031744],\n",
       "  [695, 0.0],\n",
       "  [696, 0.39634146341463417],\n",
       "  [697, 0.5],\n",
       "  [698, 0.0],\n",
       "  [699, 0.057142857142857141],\n",
       "  [700, 0.18497109826589594],\n",
       "  [701, 0.0],\n",
       "  [702, 0.0],\n",
       "  [703, 0.18367346938775511],\n",
       "  [704, 0.0],\n",
       "  [705, 0.0],\n",
       "  [706, 0.75111111111111106],\n",
       "  [707, 0.64473684210526316],\n",
       "  [708, 0.37815126050420167],\n",
       "  [709, 0.0],\n",
       "  [710, 0.0],\n",
       "  [711, 0.0],\n",
       "  [712, 0.32579185520361992],\n",
       "  [714, 0.0],\n",
       "  [715, 0.0],\n",
       "  [716, 0.0],\n",
       "  [717, 0.0],\n",
       "  [718, 0.0],\n",
       "  [719, 0.0],\n",
       "  [720, 0.018575851393188854],\n",
       "  [721, 0.0],\n",
       "  [722, 0.0],\n",
       "  [723, 0.5161290322580645],\n",
       "  [725, 0.07407407407407407],\n",
       "  [726, 0.016949152542372881],\n",
       "  [727, 0.0],\n",
       "  [730, 0.0],\n",
       "  [731, 0.32475884244372988],\n",
       "  [732, 0.0],\n",
       "  [733, 0.39256865912762517],\n",
       "  [734, 0.0074074074074074077],\n",
       "  [735, 0.24637681159420291],\n",
       "  [736, 0.0],\n",
       "  [737, 0.0],\n",
       "  [738, 0.38333333333333336],\n",
       "  [739, 0.0],\n",
       "  [740, 0.39583333333333331],\n",
       "  [741, 0.14438502673796791],\n",
       "  [742, 0.010752688172043012],\n",
       "  [743, 0.0],\n",
       "  [744, 0.78735632183908044],\n",
       "  [745, 0.0],\n",
       "  [746, 0.0],\n",
       "  [747, 0.16666666666666666],\n",
       "  [749, 0.0],\n",
       "  [750, 0.034220532319391636],\n",
       "  [751, 0.0],\n",
       "  [752, 0.031135531135531136],\n",
       "  [753, 0.184],\n",
       "  [754, 0.021739130434782608],\n",
       "  [756, 0.0],\n",
       "  [757, 0.51196172248803828],\n",
       "  [758, 0.098039215686274508],\n",
       "  [759, 0.0],\n",
       "  [760, 0.0035335689045936395],\n",
       "  [761, 0.0],\n",
       "  [762, 0.0],\n",
       "  [763, 0.0],\n",
       "  [764, 0.44444444444444442],\n",
       "  [765, 0.025210084033613446],\n",
       "  [767, 0.78125],\n",
       "  [768, 0.68609865470852016],\n",
       "  [769, 0.031746031746031744],\n",
       "  [771, 0.0],\n",
       "  [773, 0.0],\n",
       "  [774, 0.0],\n",
       "  [775, 0.0],\n",
       "  [776, 0.0],\n",
       "  [777, 0.0],\n",
       "  [778, 0.19191919191919191],\n",
       "  [779, 0.28634361233480177],\n",
       "  [780, 0.0],\n",
       "  [781, 0.0898876404494382],\n",
       "  [782, 0.0],\n",
       "  [783, 0.0],\n",
       "  [784, 0.0],\n",
       "  [785, 0.0],\n",
       "  [786, 0.0],\n",
       "  [788, 0.23999999999999999],\n",
       "  [789, 0.050000000000000003],\n",
       "  [790, 0.0],\n",
       "  [791, 0.0],\n",
       "  [792, 0.0],\n",
       "  [793, 0.0945945945945946],\n",
       "  [794, 0.0],\n",
       "  [795, 0.0070422535211267607],\n",
       "  [796, 0.17192982456140352],\n",
       "  [799, 0.0],\n",
       "  [800, 0.0],\n",
       "  [801, 0.083415112855740922],\n",
       "  [802, 0.0044742729306487695],\n",
       "  [803, 0.61378205128205132],\n",
       "  [804, 0.0],\n",
       "  [805, 0.20792079207920791],\n",
       "  [808, 0.10000000000000001],\n",
       "  [810, 0.0],\n",
       "  [811, 0.0],\n",
       "  [812, 0.56818181818181823],\n",
       "  [813, 0.0037453183520599251],\n",
       "  [814, 0.21649484536082475],\n",
       "  [815, 0.0],\n",
       "  [816, 0.0],\n",
       "  [817, 0.0],\n",
       "  [818, 0.28723404255319152],\n",
       "  [819, 0.0],\n",
       "  [820, 0.0],\n",
       "  [821, 0.0],\n",
       "  [823, 0.0],\n",
       "  [824, 0.041251778093883355],\n",
       "  [826, 0.098684210526315791],\n",
       "  [829, 0.0],\n",
       "  [830, 0.41346153846153844],\n",
       "  [832, 0.44144144144144143],\n",
       "  [833, 0.72340425531914898],\n",
       "  [836, 0.0],\n",
       "  [837, 1.0],\n",
       "  [838, 0.18390804597701149],\n",
       "  [839, 0.0052770448548812663],\n",
       "  [840, 0.0],\n",
       "  [842, 0.0],\n",
       "  [843, 0.5],\n",
       "  [844, 0.23660714285714285],\n",
       "  [845, 0.0],\n",
       "  [846, 0.044642857142857144],\n",
       "  [847, 0.0],\n",
       "  [848, 0.0],\n",
       "  [849, 0.0],\n",
       "  [850, 0.63917525773195871],\n",
       "  [851, 0.0],\n",
       "  [852, 0.0],\n",
       "  [853, 0.0],\n",
       "  [854, 0.10000000000000001],\n",
       "  [855, 0.10140845070422536],\n",
       "  [856, 0.67500000000000004],\n",
       "  [857, 0.94444444444444442],\n",
       "  [858, 0.0],\n",
       "  [859, 0.0],\n",
       "  [860, 0.0],\n",
       "  [861, 0.026737967914438502],\n",
       "  [862, 0.0],\n",
       "  [863, 0.5],\n",
       "  [864, 0.16417910447761194],\n",
       "  [865, 0.46491228070175439],\n",
       "  [866, 0.33333333333333331],\n",
       "  [867, 0.0],\n",
       "  [868, 0.0],\n",
       "  [869, 0.080745341614906832],\n",
       "  [870, 0.21428571428571427],\n",
       "  [871, 0.0],\n",
       "  [872, 0.085714285714285715],\n",
       "  [873, 0.81512605042016806],\n",
       "  [874, 0.0],\n",
       "  [875, 0.0],\n",
       "  [876, 0.0],\n",
       "  [877, 0.91666666666666663],\n",
       "  [878, 0.34166666666666667],\n",
       "  [879, 0.075949367088607597],\n",
       "  [880, 0.0],\n",
       "  [881, 0.16666666666666666],\n",
       "  [882, 0.35398230088495575],\n",
       "  [883, 0.0],\n",
       "  [884, 0.0],\n",
       "  [885, 0.18699186991869918],\n",
       "  [886, 0.74285714285714288],\n",
       "  [887, 0.15816326530612246],\n",
       "  [889, 0.0],\n",
       "  [890, 0.0],\n",
       "  [891, 0.93333333333333335],\n",
       "  [892, 0.0],\n",
       "  [893, 1.0],\n",
       "  [894, 0.0072992700729927005],\n",
       "  [897, 0.0],\n",
       "  [898, 0.66666666666666663],\n",
       "  [899, 0.0],\n",
       "  [900, 0.5],\n",
       "  [902, 0.0],\n",
       "  [903, 0.0],\n",
       "  [904, 0.0],\n",
       "  [905, 0.42499999999999999],\n",
       "  [908, 0.0],\n",
       "  [909, 0.0],\n",
       "  [910, 0.0],\n",
       "  [911, 0.0],\n",
       "  [912, 0.081632653061224483],\n",
       "  [913, 0.1130952380952381],\n",
       "  [914, 1.0],\n",
       "  [915, 0.0],\n",
       "  [916, 0.66666666666666663],\n",
       "  [918, 0.0],\n",
       "  [919, 0.0],\n",
       "  [920, 0.0],\n",
       "  [921, 0.0],\n",
       "  [922, 0.0],\n",
       "  [923, 0.0],\n",
       "  [924, 0.54545454545454541],\n",
       "  [925, 0.0],\n",
       "  [926, 0.0],\n",
       "  [927, 0.0],\n",
       "  [928, 0.0],\n",
       "  [929, 0.075471698113207544],\n",
       "  [930, 0.0],\n",
       "  [931, 0.29714285714285715],\n",
       "  [932, 0.0],\n",
       "  [933, 0.16562499999999999],\n",
       "  [934, 0.0],\n",
       "  [937, 0.0],\n",
       "  [938, 1.0],\n",
       "  [939, 0.02564102564102564],\n",
       "  [940, 0.0],\n",
       "  [941, 0.36363636363636365],\n",
       "  [942, 0.071022727272727279],\n",
       "  [943, 0.081447963800904979],\n",
       "  [944, 0.0],\n",
       "  [945, 0.0],\n",
       "  [946, 0.0],\n",
       "  [947, 0.0],\n",
       "  [948, 0.0],\n",
       "  [949, 0.0],\n",
       "  [951, 0.10526315789473684],\n",
       "  [952, 0.45161290322580644],\n",
       "  [953, 0.0],\n",
       "  [954, 0.0],\n",
       "  [955, 0.0],\n",
       "  [956, 0.25782493368700266],\n",
       "  [957, 0.25],\n",
       "  [958, 0.21111111111111111],\n",
       "  [959, 0.0],\n",
       "  [960, 0.0],\n",
       "  [961, 0.25],\n",
       "  [962, 0.0],\n",
       "  [963, 0.0099255583126550868],\n",
       "  [964, 0.035087719298245612],\n",
       "  [965, 0.10975609756097561],\n",
       "  [967, 0.15966386554621848],\n",
       "  [968, 0.5],\n",
       "  [969, 0.0],\n",
       "  [970, 0.020408163265306121],\n",
       "  [971, 0.0],\n",
       "  [972, 0.33670033670033672],\n",
       "  [973, 0.0],\n",
       "  [974, 0.37894736842105264],\n",
       "  [975, 0.0],\n",
       "  [976, 0.0],\n",
       "  [977, 0.0],\n",
       "  [978, 0.0],\n",
       "  [979, 0.12121212121212122],\n",
       "  [980, 0.059602649006622516],\n",
       "  [981, 0.16501650165016502],\n",
       "  [982, 0.090909090909090912],\n",
       "  [983, 0.0],\n",
       "  [984, 0.0],\n",
       "  [985, 0.0],\n",
       "  [988, 0.0],\n",
       "  [989, 0.0],\n",
       "  [990, 0.0],\n",
       "  [991, 0.0054200542005420054],\n",
       "  [992, 0.0],\n",
       "  [993, 0.0],\n",
       "  [994, 0.075376884422110546],\n",
       "  [996, 0.0],\n",
       "  [997, 0.085034013605442174],\n",
       "  [998, 0.0],\n",
       "  [999, 0.54216867469879515],\n",
       "  [1000, 0.7668539325842697],\n",
       "  [1001, 0.062880324543610547],\n",
       "  [1002, 0.0],\n",
       "  [1003, 0.10526315789473684],\n",
       "  [1004, 0.066666666666666666],\n",
       "  [1005, 0.57446808510638303],\n",
       "  [1006, 0.87804878048780488],\n",
       "  [1007, 0.066298342541436461],\n",
       "  [1008, 0.5625],\n",
       "  [1009, 0.14999999999999999],\n",
       "  [1010, 0.0],\n",
       "  [1011, 0.065666041275797379],\n",
       "  [1012, 0.72499999999999998],\n",
       "  [1014, 0.0],\n",
       "  [1015, 0.32417582417582419],\n",
       "  [1016, 0.0],\n",
       "  [1018, 0.0],\n",
       "  [1019, 0.51948051948051943],\n",
       "  [1020, 0.38461538461538464],\n",
       "  [1021, 0.59566787003610111],\n",
       "  [1022, 0.029999999999999999],\n",
       "  [1024, 0.72499999999999998],\n",
       "  [1025, 0.058823529411764705],\n",
       "  [1026, 0.0],\n",
       "  [1028, 0.41150442477876104],\n",
       "  [1029, 0.66666666666666663],\n",
       "  [1030, 0.0],\n",
       "  [1031, 0.0],\n",
       "  [1032, 0.5714285714285714],\n",
       "  [1033, 0.0],\n",
       "  [1034, 0.0],\n",
       "  [1035, 0.20540540540540542],\n",
       "  [1036, 0.30864197530864196],\n",
       "  [1038, 0.0],\n",
       "  [1039, 0.049504950495049507],\n",
       "  [1040, 0.0],\n",
       "  [1041, 0.16666666666666666],\n",
       "  [1042, 0.022792022792022793],\n",
       "  [1043, 0.040000000000000001],\n",
       "  [1044, 0.28582494190549962],\n",
       "  [1045, 0.23728813559322035],\n",
       "  [1046, 0.013888888888888888],\n",
       "  [1047, 0.30194805194805197],\n",
       "  [1049, 0.5],\n",
       "  [1050, 0.080246913580246909],\n",
       "  [1051, 0.0],\n",
       "  [1052, 0.0],\n",
       "  [1053, 0.0],\n",
       "  [1055, 0.0625],\n",
       "  [1056, 0.0],\n",
       "  [1058, 0.0],\n",
       "  [1060, 0.92000000000000004],\n",
       "  [1061, 0.0],\n",
       "  [1062, 0.83870967741935487],\n",
       "  [1063, 0.0],\n",
       "  [1064, 0.27659574468085107],\n",
       "  [1065, 0.0],\n",
       "  [1066, 0.51141552511415522],\n",
       "  [1067, 0.0],\n",
       "  [1068, 0.26000000000000001],\n",
       "  [1069, 0.5],\n",
       "  [1070, 0.0],\n",
       "  [1071, 0.0053191489361702126],\n",
       "  [1072, 0.33333333333333331],\n",
       "  [1073, 0.0],\n",
       "  [1074, 0.0],\n",
       "  [1076, 0.73333333333333328],\n",
       "  [1077, 0.065573770491803282],\n",
       "  [1079, 0.0],\n",
       "  [1080, 0.0],\n",
       "  [1081, 0.80681818181818177],\n",
       "  [1082, 0.40404040404040403],\n",
       "  [1083, 0.46875],\n",
       "  [1084, 0.0],\n",
       "  [1085, 0.14655172413793102],\n",
       "  [1086, 0.0],\n",
       "  [1087, 0.39622641509433965],\n",
       "  [1088, 0.0],\n",
       "  [1089, 0.020833333333333332],\n",
       "  [1090, 0.2781954887218045],\n",
       "  [1091, 0.03125],\n",
       "  [1092, 0.42548076923076922],\n",
       "  [1093, 0.30864197530864196],\n",
       "  [1094, 0.0],\n",
       "  [1095, 0.81034482758620685],\n",
       "  [1096, 0.14141414141414141],\n",
       "  [1097, 0.0],\n",
       "  [1098, 0.0],\n",
       "  [1099, 0.40000000000000002],\n",
       "  [1100, 0.5],\n",
       "  [1101, 0.0039215686274509803],\n",
       "  [1102, 0.47058823529411764],\n",
       "  [1103, 0.50413223140495866],\n",
       "  [1104, 0.0],\n",
       "  [1105, 0.51774530271398744],\n",
       "  [1106, 0.0],\n",
       "  [1108, 0.25],\n",
       "  [1109, 0.0],\n",
       "  [1110, 0.0],\n",
       "  [1111, 0.0],\n",
       "  [1112, 0.0],\n",
       "  [1113, 0.0],\n",
       "  [1114, 0.022988505747126436],\n",
       "  [1115, 0.34234234234234234],\n",
       "  [1116, 0.0],\n",
       "  [1117, 0.0],\n",
       "  [1119, 0.67213114754098358],\n",
       "  [1120, 0.14999999999999999],\n",
       "  [1121, 0.0],\n",
       "  [1123, 0.0],\n",
       "  [1124, 0.014705882352941176],\n",
       "  [1125, 0.4621212121212121],\n",
       "  [1126, 0.0],\n",
       "  [1127, 0.060737527114967459],\n",
       "  [1128, 0.0],\n",
       "  ...]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gavg_pc_2_eq0\n",
      "gavg_pc_4_eq24\n"
     ]
    }
   ],
   "source": [
    "for k in procs:\n",
    "    print(k)\n",
    "    df_tmp = pd.DataFrame(procs[k])\n",
    "    df_tmp.columns = ['group_1', k]\n",
    "    \n",
    "    data = pd.merge(data, df_tmp, on='group_1', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['achar_10_adate_pos'] = (data.adate_daynum - data.achar_10_adate_min) / data.achar_10_adate_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409834"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['leak_fillmask'] = data['outcome_filled'].isnull()\n",
    "data.leak_fillmask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_dreduct = False\n",
    "\n",
    "try:\n",
    "    dreduct = pickle.load(open('dreduct7h.pkl', 'rb'))\n",
    "except:\n",
    "    dreduct = {}\n",
    "    write_dreduct = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368 possible columns post-heating\n"
     ]
    }
   ],
   "source": [
    "# fixme?  onehot-values is still used as target fields\n",
    "do_oneheat = ['adate_dayofweek', 'activity_category', 'group_1_bin']\n",
    "dont_oneheat = ['pchar_38', 'achar_10', 'achar_10_reduced'] # *char* is heated unless listed here\n",
    "\n",
    "onehot_values = {}\n",
    "tot = 0\n",
    "\n",
    "for k in data.keys():\n",
    "    if k in dont_oneheat:\n",
    "        continue\n",
    "        \n",
    "    if 'achar_10' in k: # block all achar_10 derivatives\n",
    "        continue\n",
    "        \n",
    "    if 'char' in k or k in do_oneheat:\n",
    "        onehot_values[k] = sorted(data[k].unique())\n",
    "        tot += len(onehot_values[k])\n",
    "        \n",
    "print(tot, 'possible columns post-heating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ALL test targets with 0.0/1.0 average are fully/accurately inferred in the test set... \n",
    "\n",
    "if 'grouplist' not in dreduct:\n",
    "\n",
    "    dreduct['grouplist_all0'] = []\n",
    "    dreduct['grouplist_all1'] = []\n",
    "    dreduct['grouplist'] = []\n",
    "    count = 0\n",
    "\n",
    "    for g in data.groupby(['group_1'], sort=False):\n",
    "        if len(g[1]) > 100:\n",
    "            m = g[1].outcome.mean()\n",
    "            if m != 0 and m != 1:\n",
    "                #print(g[0], len(g[1]), g[1].outcome.mean())\n",
    "                dreduct['grouplist'].append(g[0])\n",
    "\n",
    "                count += len(g[1])\n",
    "            elif m == 0:\n",
    "                dreduct['grouplist_all0'].append(g[0])\n",
    "            elif m == 1:\n",
    "                dreduct['grouplist_all1'].append(g[0])\n",
    "        else:\n",
    "            dreduct['grouplist'].append(g[0])\n",
    "\n",
    "            count += len(g[1])\n",
    "\n",
    "    print(len(dreduct['grouplist']), len(dreduct['grouplist_all0']), len(dreduct['grouplist_all1']), count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2197291 498687 2695978\n",
      "1454634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "158242"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_traintest():\n",
    "    testset = np.where(data['outcome'].isnull())\n",
    "    trainset = np.where(~data['outcome'].isnull())\n",
    "\n",
    "    return trainset, testset, data.iloc[trainset], data.iloc[testset]\n",
    "\n",
    "trainset, testset, train, test = split_traintest()\n",
    "\n",
    "print(len(train), len(test), len(data))\n",
    "\n",
    "if 'trainmask' not in dreduct:\n",
    "    mask = np.full(len(train), False, dtype=np.bool)\n",
    "    for g in dreduct['grouplist_all0']:\n",
    "        mask = np.logical_or(mask, train.group_1 == g)\n",
    "    for g in dreduct['grouplist_all1']:\n",
    "        mask = np.logical_or(mask, train.group_1 == g)\n",
    "        \n",
    "    dreduct['trainmask'] = mask\n",
    "    \n",
    "mask = dreduct['trainmask'].copy()\n",
    "    \n",
    "print(np.sum(mask))\n",
    "\n",
    "# Need to copy since we're going to add another column\n",
    "train_cut = train.iloc[np.where(np.logical_not(mask))].copy()\n",
    "\n",
    "cols = train.columns.copy()\n",
    "cols = cols.drop('activity_id')\n",
    "train_dups = train_cut.duplicated(subset=cols)\n",
    "\n",
    "train_cut_dedup = train_cut[~train_dups]\n",
    "train_cut_dups = train_cut[train_dups]\n",
    "\n",
    "train_cut_dedup_leaks = train_cut_dedup.iloc[np.where(train_cut_dedup.leak_fillmask.values)]\n",
    "len(train_cut_dedup_leaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "stratkey = 'people_id'\n",
    "\n",
    "if 'pplbuckets' not in dreduct:\n",
    "    balls = []\n",
    "    for p in train_cut_dedup.groupby([stratkey]):\n",
    "        balls.append([p[0], len(p[1]), p[1].outcome.mean()])\n",
    "\n",
    "    dreduct['pplbuckets'] = sorted(balls, key=itemgetter(2), reverse=True)\n",
    "else:\n",
    "    balls = dreduct['pplbuckets'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if write_dreduct:\n",
    "    pickle.dump(dreduct, open('dreduct7h.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This assumes vc is sorted by whatever you want stratified\n",
    "def dosplit_rr(df, vc, folds, fuzz = (43254, .5, 4)):\n",
    "    if fuzz is not None:\n",
    "        np.random.seed(fuzz[0])\n",
    "    \n",
    "    bcount = np.zeros(folds)\n",
    "    \n",
    "    buckets = []\n",
    "    for f in range(folds):\n",
    "        buckets.append([])\n",
    "    \n",
    "    ballpit = copy.deepcopy(balls)\n",
    "    \n",
    "    runs = 0\n",
    "    \n",
    "    tot = 0\n",
    "    \n",
    "    while len(ballpit):\n",
    "        runs += 1\n",
    "        sel = 0\n",
    "        r = np.random.rand()\n",
    "        if r < fuzz[1]:\n",
    "            sel = int((fuzz[2] / fuzz[1]) * r)\n",
    "            if sel >= len(ballpit):\n",
    "                sel = len(ballpit) - 1\n",
    "\n",
    "        tot += sel\n",
    "                \n",
    "        v = ballpit[sel]\n",
    "        del ballpit[sel]\n",
    "                \n",
    "        selbucket = np.argsort(bcount)[0]\n",
    "        \n",
    "        buckets[selbucket].append(v[0])\n",
    "        bcount[selbucket] += v[1]\n",
    "    \n",
    "    print(len(balls), runs, tot)\n",
    "    \n",
    "    return buckets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53036 53036 19603\n"
     ]
    }
   ],
   "source": [
    "folds = 4\n",
    "\n",
    "source = train_cut_dedup\n",
    "pidsets_grouped = dosplit_rr(source, balls, folds, fuzz = (123456, 0.25, 4))\n",
    "\n",
    "cv_train = []\n",
    "cv_train_leak = []\n",
    "\n",
    "cv_val = []\n",
    "cv_val_leak = []\n",
    "cv_val_dups = []\n",
    "\n",
    "pu = []\n",
    "\n",
    "for p in pidsets_grouped:\n",
    "    cv_train.append(source[~source[stratkey].isin(p)])\n",
    "    cv_val.append(source[source[stratkey].isin(p)].copy()) # copy val since we need to add a field for unique groups\n",
    "    \n",
    "    pu.append(list(cv_val[-1][stratkey].unique()))\n",
    "\n",
    "    cv_train_leak.append(cv_train[-1].iloc[np.where(cv_train[-1].leak_fillmask.values)])\n",
    "    cv_val_leak.append(cv_val[-1].iloc[np.where(cv_val[-1].leak_fillmask.values)].copy())\n",
    "    \n",
    "    # This is directly from train_cut, bypassing duplicate and leak (but not skewed-group) detection\n",
    "    cv_val_dups.append(train_cut[train_cut[stratkey].isin(p)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optional test to compute which cv_val items have unique group_1's\n",
    "if False:\n",
    "    for fold in range(folds):\n",
    "\n",
    "        groups_train = sorted(cv_train[fold].group_1.unique())\n",
    "        groups_val = sorted(cv_val_leak[fold].group_1.unique())\n",
    "\n",
    "        ugroup_mask = np.full(len(cv_val_leak[fold]), False, dtype=np.bool)\n",
    "\n",
    "        cc = 0\n",
    "        cl = []\n",
    "        for g in cv_val[fold].groupby(['group_1']):\n",
    "            if g[0] not in groups_train:\n",
    "                cl.append(g[0])\n",
    "                cc += len(g[1])\n",
    "\n",
    "                ugroup_mask = np.logical_or(ugroup_mask, cv_val_leak[fold].group_1 == g[0])\n",
    "\n",
    "        cv_val_leak[fold]['ugroup_mask'] = ugroup_mask\n",
    "        \n",
    "        print(fold, cv_val_leak[fold].ugroup_mask.sum(), len(cv_val_leak[fold]))\n",
    "\n",
    "# 0 38542 39699\n",
    "# 1 38630 40117\n",
    "# 2 37681 39041\n",
    "# 3 37402 38408\n",
    "# ^ cv_val_leak results (xgb6 LB.992 run) - group_1 is almost ENTIRELY unique in xgb's eval set.  LEAKAGE!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108850 0.6027101515847496\n",
      "0 40120 0.46061814556331004 170989 0.5993017094666908\n",
      "108850 0.6026917776757005\n",
      "1 37933 0.4507948224501094 171020 0.5941410361361245\n",
      "108849 0.6026789405506711\n",
      "2 39747 0.44247364580974663 176491 0.6191193885240607\n",
      "108879 0.6025220657794432\n",
      "3 40442 0.45398348251817416 170489 0.5993641818533747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "# ppl_370270/'group 27940' is 55k of *mostly* 0's, any bad prediction in it kills CV!\n",
    "\n",
    "for f in range(0, folds):\n",
    "    if (370270 in pu[f]):\n",
    "        cv_val_dups[f] = cv_val_dups[f][cv_val_dups[f]['people_id'] != 370270]\n",
    "\n",
    "    if 'group 27940' in cv_val_dups[f]['group_1'].unique():\n",
    "        cv_val_dups[f] = cv_val_dups[f][cv_val_dups[f]['group_1'] != 'group 27940']\n",
    "        \n",
    "    print(len(cv_val[f]), cv_val[f].outcome.mean())\n",
    "    print(f, len(cv_val_leak[f]), cv_val_leak[f].outcome.mean(), len(cv_val_dups[f]), cv_val_dups[f].outcome.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "noise = .095\n",
    "q = 20\n",
    "\n",
    "def buildmatrix(df, oneheat=False, linear=False):\n",
    "    matrices = []    \n",
    "    rows = []\n",
    "    \n",
    "    rows.append(df.pchar_38.values)\n",
    "#    rows.append(np.busday_count(df.pdate.values.astype('datetime64[D]'), \n",
    "#                         df.adate.values.astype('datetime64[D]')))\n",
    " \n",
    "    rows.append(df.business_days_delta.values)\n",
    "    \n",
    "    rows.append(df.people_per_group.values)\n",
    "    \n",
    "    if linear:\n",
    "        #rows.append(df.people_per_group_adate.values / df.people_per_group.values)\n",
    "        rows.append(df.events_per_group_adate.values / df.people_per_group_adate.values)\n",
    "    \n",
    "    if not linear:\n",
    "        rows.append(df.group_1.values)\n",
    "        rows.append(df.achar_10.values)\n",
    "        \n",
    "    rows.append(df.achar_10_adate_range.values)\n",
    "    \n",
    "    rows.append(df.gp_all0.values)\n",
    "    rows[-1] += ((np.random.rand(len(rows[-1])) - .5) * noise)\n",
    "    rows[-1] = ((rows[-1] * (100 * q)) + (q / 2)) // 100 / q\n",
    "    \n",
    "    rows.append(df.gp_all1.values)\n",
    "    rows[-1] += ((np.random.rand(len(rows[-1])) - .5) * noise)\n",
    "    rows[-1] = ((rows[-1] * (100 * q)) + (q / 2)) // 100 / q\n",
    "    \n",
    "    rows.append(df.gp_mixed.values)\n",
    "    rows[-1] += ((np.random.rand(len(rows[-1])) - .5) * noise)\n",
    "    rows[-1] = ((rows[-1] * (100 * q)) + (q / 2)) // 100 / q\n",
    "\n",
    "    # Early linear analysis (xgb7h) said this has a .015 rcorr^2 when binned like this\n",
    "    tmp = df.achar_10_adate_pos.values\n",
    "    tmp = np.floor(tmp * 1000) / 1000\n",
    "    tmp[np.isnan(tmp)] = -1\n",
    "    rows.append(tmp)\n",
    "        \n",
    "    rows.append(df.adate_daynum.values)\n",
    "    \n",
    "    if not linear:\n",
    "        tmp = df.adate_gap.values\n",
    "        tmp[np.isnan(tmp)] = df.adate_daynum.values[np.isnan(tmp)]\n",
    "        rows.append(tmp) # TODO: replace nan's for linear model\n",
    "        \n",
    "    rows.append(df.pdate_daynum.values)\n",
    "    \n",
    "    '''\n",
    "    mask = df.people_per_group == 1\n",
    "    mask = np.logical_and(mask, df.activity_category <= 4)\n",
    "    mask = np.logical_and(mask, df.pchar_25 == 0)\n",
    "    #flist.append('Xlowerprob_mask')\n",
    "    rows.append(np.int8(mask))\n",
    "    \n",
    "    #mask = np.logical_and(mask, df.group_1 < 17871.5)\n",
    "    mask2 = np.logical_and(mask, df.pchar_4 == 0)\n",
    "    #flist.append('Xlowprob_mask')\n",
    "    rows.append(np.int8(mask2))\n",
    "\n",
    "    mask3 = np.logical_and(mask, df.group_1 < 17871.5)\n",
    "    #flist.append('Xlowprob_mask2')\n",
    "    rows.append(np.int8(mask3))\n",
    "    '''\n",
    "    \n",
    "    rows.append(df.gavg_pc_2_eq0)\n",
    "    rows.append(df.gavg_pc_4_eq24)\n",
    "\n",
    "\n",
    "#    rows.append(df.outcome_filled_prevday.values)\n",
    "#    rows.append(df.outcome_filled_nextday.values)\n",
    "\n",
    "    matrices.append(csr_matrix(np.array(rows).T))\n",
    "    rows = []\n",
    "\n",
    "    if oneheat or linear:\n",
    "        curitem = None\n",
    "        for i in range(len(onehot_keys)):\n",
    "            k = onehot_keys[i]\n",
    "\n",
    "            if k[0] != curitem:\n",
    "                usedmask = np.full(len(df), False, dtype=np.bool)\n",
    "                curitem = k[0]\n",
    "\n",
    "            if k[1] != None:\n",
    "                rows.append(np.array(df[k[0]] == k[1]))\n",
    "                usedmask[np.where(df[k[0]] == k[1])] = True\n",
    "            else:\n",
    "                rows.append(~usedmask)\n",
    "\n",
    "            if len(rows) >= 128:\n",
    "                matrices.append((np.array(rows).T))\n",
    "                #print(len(matrices))\n",
    "                rows = []\n",
    "\n",
    "        if len(rows) > 0:\n",
    "            matrices.append((np.array(rows).T))\n",
    "            rows = []\n",
    "\n",
    "        rv = hstack(matrices, format='csr')\n",
    "        print(rv.shape)\n",
    "        return rv\n",
    "    else:\n",
    "        for k in onehot_values.keys():\n",
    "            tmp = df[k].values.astype(np.float64)\n",
    "            #if np.sum(tmp[tmp == -1]):\n",
    "                #print(k, np.min(tmp))\n",
    "            #tmp[tmp == -1] = np.nan\n",
    "            matrices.append(csr_matrix(tmp.reshape(len(df), 1)))\n",
    "            \n",
    "        #matrices = matrices.todense()\n",
    "        #matrices.append(np.array(rows).T)\n",
    "        return hstack(matrices)\n",
    "        \n",
    "        #output = np.hstack(matrices)\n",
    "        #output[np.isnan(output)] = -1\n",
    "\n",
    "        #return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "mat_train = {}\n",
    "mat_val = {}\n",
    "mat_val_dups = {}\n",
    "dtrain = {}\n",
    "dval = {}\n",
    "dval_dups = {}\n",
    "\n",
    "val_source = cv_val_leak\n",
    "\n",
    "dooneheat = False\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for f in range(folds):\n",
    "    print(f)\n",
    "    \n",
    "    mat_train[f] = buildmatrix(cv_train_leak[f], dooneheat)\n",
    "    dtrain[f] = xgb.DMatrix(mat_train[f], label=cv_train_leak[f].outcome.values, missing=-1)\n",
    "\n",
    "    mat_val[f] = buildmatrix(val_source[f], dooneheat)\n",
    "    dval[f] = xgb.DMatrix(mat_val[f], label=val_source[f].outcome.values, missing=-1)\n",
    "\n",
    "    mat_val_dups[f] = buildmatrix(cv_val_dups[f], dooneheat)\n",
    "    dval_dups[f] = xgb.DMatrix(mat_val_dups[f], label=cv_val_dups[f].outcome.values, missing=-1)\n",
    "    \n",
    "mat_test = buildmatrix(test, False)\n",
    "dtest = xgb.DMatrix(mat_test, missing=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XXX: need way to pass this through?\n",
    "curfold = 0\n",
    "\n",
    "def feval_procleak(yhat, y):\n",
    "    if (len(yhat) != len(cv_val_dups[curfold])):\n",
    "        return \"auc\", sklearn.metrics.roc_auc_score(y.get_label(), yhat)\n",
    "    \n",
    "    yhat_f = yhat.copy()\n",
    "    \n",
    "    locs = np.where(~cv_val_dups[curfold].leak_fillmask)\n",
    "    yhat_f[locs] = cv_val_dups[curfold].outcome_filled.values[locs]\n",
    "    \n",
    "    return \"auc\", sklearn.metrics.roc_auc_score(y.get_label(), yhat_f)\n",
    "    #return \"auc\", get_leakpreds(curfold, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dfpreds(preds, cv_df):\n",
    "    cv_val_preds = []\n",
    "    for f in range(folds):\n",
    "        cv_val_preds.append(cv_df[f][['activity_id', 'outcome', 'outcome_filled', 'outcome_filled_nona', 'leak_fillmask']].copy())\n",
    "\n",
    "        cv_val_preds[f]['pred_outcome'] = preds[f]\n",
    "        cv_val_preds[f]['pred_outcomel'] = preds[f]\n",
    "        \n",
    "        mask = np.where(~cv_val_preds[f].leak_fillmask)\n",
    "        cv_val_preds[f]['pred_outcomel'].values[mask] = cv_df[f]['outcome_filled'].values[mask]\n",
    "        \n",
    "        print(f,\n",
    "              sklearn.metrics.roc_auc_score(cv_val_preds[f]['outcome'].values, cv_val_preds[f]['pred_outcome'].values),\n",
    "              sklearn.metrics.roc_auc_score(cv_val_preds[f]['outcome'].values, cv_val_preds[f]['pred_outcomel'].values))\n",
    "        \n",
    "    output = pd.concat(cv_val_preds)\n",
    "    \n",
    "    print(sklearn.metrics.roc_auc_score(output['outcome'].values, output['pred_outcome'].values),\n",
    "          sklearn.metrics.roc_auc_score(output['outcome'].values, output['pred_outcomel'].values))\n",
    "    \n",
    "    return output\n",
    "    \n",
    "\n",
    "def build_dfpreds_xgb(bst, cv_mat = dval_dups, cv_df = cv_val_dups):\n",
    "    preds = []\n",
    "    for f in range(folds):\n",
    "        print(bst[f].attributes())\n",
    "        try:\n",
    "            preds.append(bst[f].predict(cv_mat[f], ntree_limit=bst[f].best_ntree_limit))\n",
    "        except:\n",
    "            preds.append(bst[f].predict(cv_mat[f]))\n",
    "            preds[-1] = preds[-1].clip(0.001, .999)\n",
    "\n",
    "    df_preds = build_dfpreds(preds, cv_df)\n",
    "    return preds, df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.733013\teval_dups-auc:0.939142\teval-auc:0.737786\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.767088\teval_dups-auc:0.941211\teval-auc:0.748131\n",
      "[100]\ttrain-auc:0.7723\teval_dups-auc:0.941378\teval-auc:0.749035\n",
      "[150]\ttrain-auc:0.777294\teval_dups-auc:0.941512\teval-auc:0.749614\n",
      "[200]\ttrain-auc:0.782055\teval_dups-auc:0.941617\teval-auc:0.750082\n",
      "[250]\ttrain-auc:0.785827\teval_dups-auc:0.942\teval-auc:0.7507\n",
      "[300]\ttrain-auc:0.79047\teval_dups-auc:0.942184\teval-auc:0.750578\n",
      "[350]\ttrain-auc:0.794643\teval_dups-auc:0.942261\teval-auc:0.750454\n",
      "[400]\ttrain-auc:0.799153\teval_dups-auc:0.942285\teval-auc:0.750547\n",
      "[450]\ttrain-auc:0.8039\teval_dups-auc:0.942189\teval-auc:0.74995\n",
      "[500]\ttrain-auc:0.807723\teval_dups-auc:0.942218\teval-auc:0.750023\n",
      "[550]\ttrain-auc:0.811819\teval_dups-auc:0.942228\teval-auc:0.750094\n",
      "[600]\ttrain-auc:0.815989\teval_dups-auc:0.942248\teval-auc:0.750313\n",
      "[650]\ttrain-auc:0.819657\teval_dups-auc:0.942202\teval-auc:0.750059\n",
      "[700]\ttrain-auc:0.82327\teval_dups-auc:0.94219\teval-auc:0.750091\n",
      "[750]\ttrain-auc:0.826598\teval_dups-auc:0.942223\teval-auc:0.750273\n",
      "Stopping. Best iteration:\n",
      "[276]\ttrain-auc:0.788269\teval_dups-auc:0.942166\teval-auc:0.750867\n",
      "\n",
      "[0]\ttrain-auc:0.733682\teval_dups-auc:0.94372\teval-auc:0.733525\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.770848\teval_dups-auc:0.946313\teval-auc:0.751249\n",
      "[100]\ttrain-auc:0.775888\teval_dups-auc:0.946762\teval-auc:0.753405\n",
      "[150]\ttrain-auc:0.779824\teval_dups-auc:0.946956\teval-auc:0.754241\n",
      "[200]\ttrain-auc:0.783541\teval_dups-auc:0.947096\teval-auc:0.755109\n",
      "[250]\ttrain-auc:0.787719\teval_dups-auc:0.947302\teval-auc:0.755349\n",
      "[300]\ttrain-auc:0.792168\teval_dups-auc:0.947533\teval-auc:0.755394\n",
      "[350]\ttrain-auc:0.795856\teval_dups-auc:0.947686\teval-auc:0.755451\n",
      "[400]\ttrain-auc:0.799382\teval_dups-auc:0.947796\teval-auc:0.755805\n",
      "[450]\ttrain-auc:0.802926\teval_dups-auc:0.947872\teval-auc:0.756155\n",
      "[500]\ttrain-auc:0.806135\teval_dups-auc:0.947911\teval-auc:0.756528\n",
      "[550]\ttrain-auc:0.809438\teval_dups-auc:0.947979\teval-auc:0.756917\n",
      "[600]\ttrain-auc:0.813085\teval_dups-auc:0.948032\teval-auc:0.757283\n",
      "[650]\ttrain-auc:0.815846\teval_dups-auc:0.94805\teval-auc:0.757312\n",
      "[700]\ttrain-auc:0.81935\teval_dups-auc:0.948066\teval-auc:0.757423\n",
      "[750]\ttrain-auc:0.822348\teval_dups-auc:0.948067\teval-auc:0.757509\n",
      "[800]\ttrain-auc:0.825706\teval_dups-auc:0.948093\teval-auc:0.757726\n",
      "[850]\ttrain-auc:0.829336\teval_dups-auc:0.948064\teval-auc:0.757692\n",
      "[900]\ttrain-auc:0.832242\teval_dups-auc:0.948052\teval-auc:0.757774\n",
      "[950]\ttrain-auc:0.834688\teval_dups-auc:0.94804\teval-auc:0.757704\n",
      "[1000]\ttrain-auc:0.837587\teval_dups-auc:0.94804\teval-auc:0.757743\n",
      "[1050]\ttrain-auc:0.840394\teval_dups-auc:0.948043\teval-auc:0.757824\n",
      "[1100]\ttrain-auc:0.843148\teval_dups-auc:0.948009\teval-auc:0.757705\n",
      "[1150]\ttrain-auc:0.845975\teval_dups-auc:0.947989\teval-auc:0.757588\n",
      "[1200]\ttrain-auc:0.84857\teval_dups-auc:0.947987\teval-auc:0.757595\n",
      "[1250]\ttrain-auc:0.850797\teval_dups-auc:0.947939\teval-auc:0.757297\n",
      "[1300]\ttrain-auc:0.853365\teval_dups-auc:0.947937\teval-auc:0.757177\n",
      "[1350]\ttrain-auc:0.855873\teval_dups-auc:0.947949\teval-auc:0.75736\n",
      "[1400]\ttrain-auc:0.858162\teval_dups-auc:0.94794\teval-auc:0.757316\n",
      "[1450]\ttrain-auc:0.860338\teval_dups-auc:0.947958\teval-auc:0.757529\n",
      "Stopping. Best iteration:\n",
      "[993]\ttrain-auc:0.837044\teval_dups-auc:0.948053\teval-auc:0.757864\n",
      "\n",
      "[0]\ttrain-auc:0.751029\teval_dups-auc:0.949441\teval-auc:0.741135\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.778707\teval_dups-auc:0.950158\teval-auc:0.745844\n",
      "[100]\ttrain-auc:0.784516\teval_dups-auc:0.950291\teval-auc:0.745809\n",
      "[150]\ttrain-auc:0.789227\teval_dups-auc:0.950545\teval-auc:0.746784\n",
      "[200]\ttrain-auc:0.793147\teval_dups-auc:0.950592\teval-auc:0.746774\n",
      "[250]\ttrain-auc:0.797172\teval_dups-auc:0.950819\teval-auc:0.746686\n",
      "[300]\ttrain-auc:0.800722\teval_dups-auc:0.950774\teval-auc:0.746553\n",
      "[350]\ttrain-auc:0.80485\teval_dups-auc:0.950789\teval-auc:0.746694\n",
      "[400]\ttrain-auc:0.808857\teval_dups-auc:0.950722\teval-auc:0.746502\n",
      "[450]\ttrain-auc:0.812077\teval_dups-auc:0.950663\teval-auc:0.746237\n",
      "[500]\ttrain-auc:0.816097\teval_dups-auc:0.950634\teval-auc:0.746317\n",
      "[550]\ttrain-auc:0.819336\teval_dups-auc:0.950336\teval-auc:0.745996\n",
      "[600]\ttrain-auc:0.822318\teval_dups-auc:0.95023\teval-auc:0.745844\n",
      "[650]\ttrain-auc:0.825587\teval_dups-auc:0.950139\teval-auc:0.745513\n",
      "[700]\ttrain-auc:0.828824\teval_dups-auc:0.950074\teval-auc:0.745383\n",
      "Stopping. Best iteration:\n",
      "[226]\ttrain-auc:0.794891\teval_dups-auc:0.950793\teval-auc:0.747106\n",
      "\n",
      "[0]\ttrain-auc:0.746066\teval_dups-auc:0.941013\teval-auc:0.715385\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.779062\teval_dups-auc:0.944219\teval-auc:0.736485\n",
      "[100]\ttrain-auc:0.78616\teval_dups-auc:0.944384\teval-auc:0.73657\n",
      "[150]\ttrain-auc:0.790309\teval_dups-auc:0.944491\teval-auc:0.737025\n",
      "[200]\ttrain-auc:0.79419\teval_dups-auc:0.94461\teval-auc:0.736926\n",
      "[250]\ttrain-auc:0.798439\teval_dups-auc:0.94492\teval-auc:0.737303\n",
      "[300]\ttrain-auc:0.80264\teval_dups-auc:0.944861\teval-auc:0.73748\n",
      "[350]\ttrain-auc:0.80735\teval_dups-auc:0.944829\teval-auc:0.737329\n",
      "[400]\ttrain-auc:0.812352\teval_dups-auc:0.944727\teval-auc:0.736897\n",
      "[450]\ttrain-auc:0.816269\teval_dups-auc:0.94476\teval-auc:0.737107\n",
      "[500]\ttrain-auc:0.819633\teval_dups-auc:0.944764\teval-auc:0.737321\n",
      "[550]\ttrain-auc:0.823006\teval_dups-auc:0.944775\teval-auc:0.737337\n",
      "[600]\ttrain-auc:0.826658\teval_dups-auc:0.944724\teval-auc:0.736924\n",
      "[650]\ttrain-auc:0.829841\teval_dups-auc:0.944702\teval-auc:0.736692\n",
      "[700]\ttrain-auc:0.832208\teval_dups-auc:0.944643\teval-auc:0.736223\n",
      "[750]\ttrain-auc:0.83517\teval_dups-auc:0.944608\teval-auc:0.735859\n",
      "[800]\ttrain-auc:0.838121\teval_dups-auc:0.944639\teval-auc:0.735968\n",
      "Stopping. Best iteration:\n",
      "[312]\ttrain-auc:0.803766\teval_dups-auc:0.944858\teval-auc:0.73771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param = {'max_depth':10, 'eta':0.01, 'silent':1, 'objective':'binary:logistic' }\n",
    "#param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.5\n",
    "param['colsample_bytree']= 0.3\n",
    "param['min_child_weight'] = 1\n",
    "param['max_depth'] = 5\n",
    "param['booster'] = \"gbtree\"\n",
    "param['seed'] = 12345\n",
    "\n",
    "bst_d5 = {}\n",
    "#bst_linear = {} # optional\n",
    "\n",
    "for curfold in range(folds):\n",
    "#for curfold in [2]:\n",
    "    #watchlist  = [(dtrain[curfold],'train'), (dval_dups[curfold], 'eval_dups'), (dval[curfold], 'eval')]\n",
    "    watchlist  = [(dtrain[curfold],'train'), (dval_dups[curfold], 'eval_dups'), (dval[curfold], 'eval')]\n",
    "    num_round = 2000\n",
    "    early_stopping_rounds=500\n",
    "    bst_d5[curfold] = xgb.train(param, dtrain[curfold], num_round, watchlist,\n",
    "                       feval = feval_procleak,\n",
    "                       early_stopping_rounds=early_stopping_rounds, \n",
    "                       verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.737526\teval_dups-auc:0.938145\teval-auc:0.731617\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.788406\teval_dups-auc:0.940761\teval-auc:0.74626\n",
      "[100]\ttrain-auc:0.795707\teval_dups-auc:0.9412\teval-auc:0.74806\n",
      "[150]\ttrain-auc:0.799123\teval_dups-auc:0.94154\teval-auc:0.749939\n",
      "[200]\ttrain-auc:0.804308\teval_dups-auc:0.941707\teval-auc:0.750647\n",
      "[250]\ttrain-auc:0.810384\teval_dups-auc:0.942025\teval-auc:0.751326\n",
      "[300]\ttrain-auc:0.81622\teval_dups-auc:0.942224\teval-auc:0.751077\n",
      "[350]\ttrain-auc:0.82219\teval_dups-auc:0.94229\teval-auc:0.75118\n",
      "[400]\ttrain-auc:0.828129\teval_dups-auc:0.9423\teval-auc:0.751063\n",
      "[450]\ttrain-auc:0.833679\teval_dups-auc:0.942325\teval-auc:0.750974\n",
      "Stopping. Best iteration:\n",
      "[253]\ttrain-auc:0.810616\teval_dups-auc:0.942062\teval-auc:0.751395\n",
      "\n",
      "[0]\ttrain-auc:0.728005\teval_dups-auc:0.942793\teval-auc:0.726518\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.78076\teval_dups-auc:0.946814\teval-auc:0.754743\n",
      "[100]\ttrain-auc:0.787924\teval_dups-auc:0.947047\teval-auc:0.755698\n",
      "[150]\ttrain-auc:0.797162\teval_dups-auc:0.947111\teval-auc:0.756124\n",
      "[200]\ttrain-auc:0.803655\teval_dups-auc:0.947283\teval-auc:0.756979\n",
      "[250]\ttrain-auc:0.809658\teval_dups-auc:0.947593\teval-auc:0.757448\n",
      "[300]\ttrain-auc:0.816399\teval_dups-auc:0.94782\teval-auc:0.757767\n",
      "[350]\ttrain-auc:0.821225\teval_dups-auc:0.948042\teval-auc:0.758798\n",
      "[400]\ttrain-auc:0.826533\teval_dups-auc:0.948063\teval-auc:0.758689\n",
      "[450]\ttrain-auc:0.83084\teval_dups-auc:0.948118\teval-auc:0.758997\n",
      "[500]\ttrain-auc:0.835035\teval_dups-auc:0.948126\teval-auc:0.75908\n",
      "[550]\ttrain-auc:0.83929\teval_dups-auc:0.948142\teval-auc:0.759171\n",
      "[600]\ttrain-auc:0.843993\teval_dups-auc:0.948142\teval-auc:0.759131\n",
      "[650]\ttrain-auc:0.847791\teval_dups-auc:0.948153\teval-auc:0.759258\n",
      "[700]\ttrain-auc:0.851383\teval_dups-auc:0.948169\teval-auc:0.759515\n",
      "[750]\ttrain-auc:0.85545\teval_dups-auc:0.948196\teval-auc:0.759584\n",
      "[800]\ttrain-auc:0.859844\teval_dups-auc:0.948158\teval-auc:0.759305\n",
      "[850]\ttrain-auc:0.863094\teval_dups-auc:0.948135\teval-auc:0.759195\n",
      "[900]\ttrain-auc:0.866346\teval_dups-auc:0.948158\teval-auc:0.75933\n",
      "Stopping. Best iteration:\n",
      "[713]\ttrain-auc:0.852334\teval_dups-auc:0.948172\teval-auc:0.759635\n",
      "\n",
      "[0]\ttrain-auc:0.699567\teval_dups-auc:0.938054\teval-auc:0.652167\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.801931\teval_dups-auc:0.9498\teval-auc:0.743914\n",
      "[100]\ttrain-auc:0.808065\teval_dups-auc:0.950005\teval-auc:0.744078\n",
      "[150]\ttrain-auc:0.814549\teval_dups-auc:0.950189\teval-auc:0.744785\n",
      "[200]\ttrain-auc:0.820208\teval_dups-auc:0.95042\teval-auc:0.745634\n",
      "[250]\ttrain-auc:0.825924\teval_dups-auc:0.950704\teval-auc:0.746732\n",
      "[300]\ttrain-auc:0.830775\teval_dups-auc:0.950743\teval-auc:0.74679\n",
      "[350]\ttrain-auc:0.836339\teval_dups-auc:0.950778\teval-auc:0.747115\n",
      "[400]\ttrain-auc:0.840296\teval_dups-auc:0.950712\teval-auc:0.746944\n",
      "[450]\ttrain-auc:0.844804\teval_dups-auc:0.950641\teval-auc:0.747005\n",
      "[500]\ttrain-auc:0.849068\teval_dups-auc:0.950393\teval-auc:0.746904\n",
      "Stopping. Best iteration:\n",
      "[343]\ttrain-auc:0.835905\teval_dups-auc:0.950797\teval-auc:0.747266\n",
      "\n",
      "[0]\ttrain-auc:0.760048\teval_dups-auc:0.94173\teval-auc:0.720528\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[50]\ttrain-auc:0.800064\teval_dups-auc:0.943909\teval-auc:0.734463\n",
      "[100]\ttrain-auc:0.80681\teval_dups-auc:0.944216\teval-auc:0.735756\n",
      "[150]\ttrain-auc:0.812841\teval_dups-auc:0.944292\teval-auc:0.735609\n",
      "[200]\ttrain-auc:0.819178\teval_dups-auc:0.94446\teval-auc:0.73632\n",
      "[250]\ttrain-auc:0.824132\teval_dups-auc:0.944835\teval-auc:0.73677\n",
      "[300]\ttrain-auc:0.830766\teval_dups-auc:0.944766\teval-auc:0.737048\n",
      "[350]\ttrain-auc:0.836464\teval_dups-auc:0.94472\teval-auc:0.736842\n",
      "[400]\ttrain-auc:0.841741\teval_dups-auc:0.944692\teval-auc:0.736449\n",
      "[450]\ttrain-auc:0.846436\teval_dups-auc:0.944679\teval-auc:0.736406\n",
      "Stopping. Best iteration:\n",
      "[288]\ttrain-auc:0.828604\teval_dups-auc:0.94481\teval-auc:0.737097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param = {'max_depth':10, 'eta':0.01, 'silent':1, 'objective':'binary:logistic' }\n",
    "#param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.5\n",
    "param['colsample_bytree']= 0.3\n",
    "param['min_child_weight'] = 2\n",
    "param['max_depth'] = 6\n",
    "param['booster'] = \"gbtree\"\n",
    "param['seed'] = 12343\n",
    "\n",
    "bst_d6 = {}\n",
    "#bst_linear = {} # optional\n",
    "\n",
    "for curfold in range(folds):\n",
    "#for curfold in [2]:\n",
    "    #watchlist  = [(dtrain[curfold],'train'), (dval_dups[curfold], 'eval_dups'), (dval[curfold], 'eval')]\n",
    "    watchlist  = [(dtrain[curfold],'train'), (dval_dups[curfold], 'eval_dups'), (dval[curfold], 'eval')]\n",
    "    num_round = 2000\n",
    "    early_stopping_rounds=200\n",
    "    bst_d6[curfold] = xgb.train(param, dtrain[curfold], num_round, watchlist,\n",
    "                       feval = feval_procleak,\n",
    "                       early_stopping_rounds=early_stopping_rounds, \n",
    "                       verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_msg': '[253]\\ttrain-auc:0.810616\\teval_dups-auc:0.942062\\teval-auc:0.751395', 'best_score': '0.751395', 'best_iteration': '253'}\n",
      "{'best_msg': '[713]\\ttrain-auc:0.852334\\teval_dups-auc:0.948172\\teval-auc:0.759635', 'best_score': '0.759635', 'best_iteration': '713'}\n",
      "{'best_msg': '[343]\\ttrain-auc:0.835905\\teval_dups-auc:0.950797\\teval-auc:0.747266', 'best_score': '0.747266', 'best_iteration': '343'}\n",
      "{'best_msg': '[288]\\ttrain-auc:0.828604\\teval_dups-auc:0.94481\\teval-auc:0.737097', 'best_score': '0.737097', 'best_iteration': '288'}\n",
      "0 0.752733843583 0.942062045934\n",
      "1 0.752814005632 0.948171670651\n",
      "2 0.759309729488 0.950797467125\n",
      "3 0.757924213556 0.94480979979\n",
      "0.753434939162 0.946454723934\n"
     ]
    }
   ],
   "source": [
    "#m4 run r\n",
    "preds_d6, df_preds_d6 = build_dfpreds_xgb(bst_d6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_msg': '[276]\\ttrain-auc:0.788269\\teval_dups-auc:0.942166\\teval-auc:0.750867', 'best_score': '0.750867', 'best_iteration': '276'}\n",
      "{'best_msg': '[993]\\ttrain-auc:0.837044\\teval_dups-auc:0.948053\\teval-auc:0.757864', 'best_score': '0.757864', 'best_iteration': '993'}\n",
      "{'best_msg': '[226]\\ttrain-auc:0.794891\\teval_dups-auc:0.950793\\teval-auc:0.747106', 'best_score': '0.747106', 'best_iteration': '226'}\n",
      "{'best_msg': '[312]\\ttrain-auc:0.803766\\teval_dups-auc:0.944858\\teval-auc:0.73771', 'best_score': '0.73771', 'best_iteration': '312'}\n",
      "0 0.754007781301 0.942165788045\n",
      "1 0.751606304823 0.948052563567\n",
      "2 0.762290584249 0.950792528444\n",
      "3 0.758382898324 0.944857671069\n",
      "0.754353655316 0.946393075867\n"
     ]
    }
   ],
   "source": [
    "#m4 run two\n",
    "preds_d5, df_preds_d5 = build_dfpreds_xgb(bst_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_score': '0.753615', 'best_iteration': '752', 'best_msg': '[752]\\ttrain-auc:0.845992\\teval_dups-auc:0.94264\\teval-auc:0.753615'}\n",
      "{'best_score': '0.757821', 'best_iteration': '954', 'best_msg': '[954]\\ttrain-auc:0.853251\\teval_dups-auc:0.948177\\teval-auc:0.757821'}\n",
      "{'best_score': '0.743711', 'best_iteration': '141', 'best_msg': '[141]\\ttrain-auc:0.797326\\teval_dups-auc:0.950185\\teval-auc:0.743711'}\n",
      "{'best_score': '0.736786', 'best_iteration': '213', 'best_msg': '[213]\\ttrain-auc:0.804843\\teval_dups-auc:0.944807\\teval-auc:0.736786'}\n",
      "0 0.752279284087 0.942639702175\n",
      "1 0.753547690921 0.948177084922\n",
      "2 0.76067852258 0.950185196789\n",
      "3 0.759599575665 0.944806969918\n",
      "0.747293194592 0.946151591414\n"
     ]
    }
   ],
   "source": [
    "#m3\n",
    "preds_d5, df_preds_d5 = build_dfpreds_xgb(bst_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_msg': '[574]\\ttrain-auc:0.83139\\teval_dups-auc:0.941867\\teval-auc:0.748414', 'best_iteration': '574', 'best_score': '0.748414'}\n",
      "{'best_msg': '[1474]\\ttrain-auc:0.883595\\teval_dups-auc:0.947402\\teval-auc:0.753172', 'best_iteration': '1474', 'best_score': '0.753172'}\n",
      "{'best_msg': '[457]\\ttrain-auc:0.823708\\teval_dups-auc:0.949297\\teval-auc:0.740588', 'best_iteration': '457', 'best_score': '0.740588'}\n",
      "{'best_msg': '[238]\\ttrain-auc:0.805222\\teval_dups-auc:0.944347\\teval-auc:0.735669', 'best_iteration': '238', 'best_score': '0.735669'}\n",
      "0 0.748735285604 0.941867143597\n",
      "1 0.751936029323 0.947402056114\n",
      "2 0.765906384995 0.949296834144\n",
      "3 0.760626521775 0.944346827339\n",
      "0.753020170928 0.945669475544\n"
     ]
    }
   ],
   "source": [
    "#m2\n",
    "preds_d5, df_preds_d5 = build_dfpreds_xgb(bst_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_iteration': '1256', 'best_score': '0.745132', 'best_msg': '[1256]\\ttrain-auc:0.894881\\teval_dups-auc:0.941498\\teval-auc:0.745132'}\n",
      "{'best_iteration': '1999', 'best_score': '0.753396', 'best_msg': '[1999]\\ttrain-auc:0.921602\\teval_dups-auc:0.947338\\teval-auc:0.753396'}\n",
      "{'best_iteration': '811', 'best_score': '0.73237', 'best_msg': '[811]\\ttrain-auc:0.865569\\teval_dups-auc:0.948136\\teval-auc:0.73237'}\n",
      "{'best_iteration': '1043', 'best_score': '0.719873', 'best_msg': '[1043]\\ttrain-auc:0.887005\\teval_dups-auc:0.942731\\teval-auc:0.719873'}\n",
      "0 0.739538654098 0.941498369384\n",
      "1 0.737301126407 0.947338234202\n",
      "2 0.742346539954 0.948136152364\n",
      "3 0.739452499588 0.942730770974\n",
      "0.738588420596 0.944967708879\n"
     ]
    }
   ],
   "source": [
    "#m1\n",
    "preds_d5, df_preds_d5 = build_dfpreds_xgb(bst_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_msg': '[746]\\ttrain-auc:0.858042\\teval_dups-auc:0.941484\\teval-auc:0.746186', 'best_iteration': '746', 'best_score': '0.746186'}\n",
      "{'best_msg': '[239]\\ttrain-auc:0.805788\\teval_dups-auc:0.947217\\teval-auc:0.752327', 'best_iteration': '239', 'best_score': '0.752327'}\n",
      "{'best_msg': '[3]\\ttrain-auc:0.775678\\teval_dups-auc:0.948996\\teval-auc:0.740552', 'best_iteration': '3', 'best_score': '0.740552'}\n",
      "{'best_msg': '[479]\\ttrain-auc:0.831583\\teval_dups-auc:0.944428\\teval-auc:0.736211', 'best_iteration': '479', 'best_score': '0.736211'}\n",
      "0 0.753149331827 0.941484422522\n",
      "1 0.752985442728 0.947216783493\n",
      "2 0.758381677143 0.948996381774\n",
      "3 0.75686377369 0.944428114792\n",
      "0.728084245327 0.942640812557\n"
     ]
    }
   ],
   "source": [
    "#m2\n",
    "preds_d5, df_preds_d5 = build_dfpreds_xgb(bst_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.731485\teval_dups-auc:0.934826\teval-auc:0.704509\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.802087\teval_dups-auc:0.939731\teval-auc:0.736787\n",
      "[100]\ttrain-auc:0.812199\teval_dups-auc:0.939783\teval-auc:0.736208\n",
      "[150]\ttrain-auc:0.822546\teval_dups-auc:0.939908\teval-auc:0.736826\n",
      "[200]\ttrain-auc:0.832695\teval_dups-auc:0.940276\teval-auc:0.73744\n",
      "[250]\ttrain-auc:0.842626\teval_dups-auc:0.94048\teval-auc:0.738799\n",
      "[300]\ttrain-auc:0.852093\teval_dups-auc:0.940775\teval-auc:0.73987\n",
      "[350]\ttrain-auc:0.860716\teval_dups-auc:0.940863\teval-auc:0.740573\n",
      "[400]\ttrain-auc:0.869673\teval_dups-auc:0.941086\teval-auc:0.742302\n",
      "[450]\ttrain-auc:0.876158\teval_dups-auc:0.941224\teval-auc:0.743061\n",
      "[500]\ttrain-auc:0.882002\teval_dups-auc:0.94132\teval-auc:0.743588\n",
      "[550]\ttrain-auc:0.887751\teval_dups-auc:0.941451\teval-auc:0.74454\n",
      "[600]\ttrain-auc:0.893511\teval_dups-auc:0.941513\teval-auc:0.745156\n",
      "[650]\ttrain-auc:0.897729\teval_dups-auc:0.941506\teval-auc:0.74519\n",
      "[700]\ttrain-auc:0.902037\teval_dups-auc:0.941463\teval-auc:0.745151\n",
      "[750]\ttrain-auc:0.906129\teval_dups-auc:0.941506\teval-auc:0.745665\n",
      "[800]\ttrain-auc:0.909725\teval_dups-auc:0.94151\teval-auc:0.745949\n",
      "[850]\ttrain-auc:0.913454\teval_dups-auc:0.941542\teval-auc:0.746227\n",
      "[900]\ttrain-auc:0.917077\teval_dups-auc:0.941483\teval-auc:0.746268\n",
      "[950]\ttrain-auc:0.920137\teval_dups-auc:0.941434\teval-auc:0.746082\n",
      "[1000]\ttrain-auc:0.923274\teval_dups-auc:0.94138\teval-auc:0.746281\n",
      "[1050]\ttrain-auc:0.925803\teval_dups-auc:0.941335\teval-auc:0.746287\n",
      "[1100]\ttrain-auc:0.928109\teval_dups-auc:0.941335\teval-auc:0.746315\n",
      "[1150]\ttrain-auc:0.930336\teval_dups-auc:0.941329\teval-auc:0.746269\n",
      "[1200]\ttrain-auc:0.932669\teval_dups-auc:0.941332\teval-auc:0.746604\n",
      "[1250]\ttrain-auc:0.934629\teval_dups-auc:0.941339\teval-auc:0.746573\n",
      "[1300]\ttrain-auc:0.936432\teval_dups-auc:0.941294\teval-auc:0.746576\n",
      "[1350]\ttrain-auc:0.938639\teval_dups-auc:0.941246\teval-auc:0.746273\n",
      "[1400]\ttrain-auc:0.940569\teval_dups-auc:0.941239\teval-auc:0.746249\n",
      "[1450]\ttrain-auc:0.942238\teval_dups-auc:0.941232\teval-auc:0.74628\n",
      "[1500]\ttrain-auc:0.944079\teval_dups-auc:0.941238\teval-auc:0.746394\n",
      "[1550]\ttrain-auc:0.945777\teval_dups-auc:0.941298\teval-auc:0.74663\n",
      "[1600]\ttrain-auc:0.94727\teval_dups-auc:0.941269\teval-auc:0.746528\n",
      "[1650]\ttrain-auc:0.948629\teval_dups-auc:0.941303\teval-auc:0.746761\n",
      "[1700]\ttrain-auc:0.950087\teval_dups-auc:0.941262\teval-auc:0.746352\n",
      "[1750]\ttrain-auc:0.951391\teval_dups-auc:0.941249\teval-auc:0.746219\n",
      "[1800]\ttrain-auc:0.952732\teval_dups-auc:0.941218\teval-auc:0.745984\n",
      "[1850]\ttrain-auc:0.953858\teval_dups-auc:0.941215\teval-auc:0.745949\n",
      "[1900]\ttrain-auc:0.955054\teval_dups-auc:0.941192\teval-auc:0.745776\n",
      "[1950]\ttrain-auc:0.956174\teval_dups-auc:0.941211\teval-auc:0.745812\n",
      "[0]\ttrain-auc:0.73931\teval_dups-auc:0.940663\teval-auc:0.705173\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.804957\teval_dups-auc:0.944478\teval-auc:0.737718\n",
      "[100]\ttrain-auc:0.814667\teval_dups-auc:0.94482\teval-auc:0.73886\n",
      "[150]\ttrain-auc:0.825309\teval_dups-auc:0.945309\teval-auc:0.741818\n",
      "[200]\ttrain-auc:0.834697\teval_dups-auc:0.945806\teval-auc:0.74372\n",
      "[250]\ttrain-auc:0.843879\teval_dups-auc:0.946207\teval-auc:0.746169\n",
      "[300]\ttrain-auc:0.852247\teval_dups-auc:0.946469\teval-auc:0.747331\n",
      "[350]\ttrain-auc:0.859835\teval_dups-auc:0.946748\teval-auc:0.748964\n",
      "[400]\ttrain-auc:0.86666\teval_dups-auc:0.946806\teval-auc:0.749748\n",
      "[450]\ttrain-auc:0.872383\teval_dups-auc:0.946908\teval-auc:0.75062\n",
      "[500]\ttrain-auc:0.878851\teval_dups-auc:0.947012\teval-auc:0.751531\n",
      "[550]\ttrain-auc:0.883702\teval_dups-auc:0.947014\teval-auc:0.751482\n",
      "[600]\ttrain-auc:0.888855\teval_dups-auc:0.947121\teval-auc:0.752384\n",
      "[650]\ttrain-auc:0.893569\teval_dups-auc:0.947197\teval-auc:0.752928\n",
      "[700]\ttrain-auc:0.898271\teval_dups-auc:0.947263\teval-auc:0.753354\n",
      "[750]\ttrain-auc:0.902461\teval_dups-auc:0.947302\teval-auc:0.753461\n",
      "[800]\ttrain-auc:0.90621\teval_dups-auc:0.947354\teval-auc:0.753731\n",
      "[850]\ttrain-auc:0.910228\teval_dups-auc:0.947405\teval-auc:0.754141\n",
      "[900]\ttrain-auc:0.913704\teval_dups-auc:0.94742\teval-auc:0.7543\n",
      "[950]\ttrain-auc:0.916702\teval_dups-auc:0.94745\teval-auc:0.754802\n",
      "[1000]\ttrain-auc:0.919882\teval_dups-auc:0.947489\teval-auc:0.755248\n",
      "[1050]\ttrain-auc:0.922934\teval_dups-auc:0.947586\teval-auc:0.755806\n",
      "[1100]\ttrain-auc:0.925526\teval_dups-auc:0.947584\teval-auc:0.755901\n",
      "[1150]\ttrain-auc:0.928219\teval_dups-auc:0.947522\teval-auc:0.755829\n",
      "[1200]\ttrain-auc:0.930603\teval_dups-auc:0.947536\teval-auc:0.75591\n",
      "[1250]\ttrain-auc:0.932927\teval_dups-auc:0.947516\teval-auc:0.755873\n",
      "[1300]\ttrain-auc:0.935293\teval_dups-auc:0.947536\teval-auc:0.755898\n",
      "[1350]\ttrain-auc:0.937281\teval_dups-auc:0.947554\teval-auc:0.756127\n",
      "[1400]\ttrain-auc:0.939254\teval_dups-auc:0.947532\teval-auc:0.756134\n",
      "[1450]\ttrain-auc:0.941114\teval_dups-auc:0.947545\teval-auc:0.756407\n",
      "[1500]\ttrain-auc:0.942835\teval_dups-auc:0.947547\teval-auc:0.756498\n",
      "[1550]\ttrain-auc:0.944479\teval_dups-auc:0.947568\teval-auc:0.756692\n",
      "[1600]\ttrain-auc:0.946172\teval_dups-auc:0.947574\teval-auc:0.75672\n",
      "[1650]\ttrain-auc:0.947811\teval_dups-auc:0.94763\teval-auc:0.757058\n",
      "[1700]\ttrain-auc:0.949129\teval_dups-auc:0.947643\teval-auc:0.757123\n",
      "[1750]\ttrain-auc:0.950396\teval_dups-auc:0.947607\teval-auc:0.756946\n",
      "[1800]\ttrain-auc:0.951688\teval_dups-auc:0.947579\teval-auc:0.756921\n",
      "[1850]\ttrain-auc:0.953133\teval_dups-auc:0.947589\teval-auc:0.757245\n",
      "[1900]\ttrain-auc:0.954453\teval_dups-auc:0.947554\teval-auc:0.757154\n",
      "[1950]\ttrain-auc:0.955644\teval_dups-auc:0.947525\teval-auc:0.756929\n",
      "[0]\ttrain-auc:0.74102\teval_dups-auc:0.942024\teval-auc:0.680171\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.803655\teval_dups-auc:0.946251\teval-auc:0.717271\n",
      "[100]\ttrain-auc:0.815885\teval_dups-auc:0.946679\teval-auc:0.719891\n",
      "[150]\ttrain-auc:0.826151\teval_dups-auc:0.946952\teval-auc:0.721825\n",
      "[200]\ttrain-auc:0.835606\teval_dups-auc:0.947273\teval-auc:0.723201\n",
      "[250]\ttrain-auc:0.844974\teval_dups-auc:0.947314\teval-auc:0.724978\n",
      "[300]\ttrain-auc:0.8537\teval_dups-auc:0.947496\teval-auc:0.726344\n",
      "[350]\ttrain-auc:0.861284\teval_dups-auc:0.947632\teval-auc:0.727359\n",
      "[400]\ttrain-auc:0.868123\teval_dups-auc:0.947716\teval-auc:0.728227\n",
      "[450]\ttrain-auc:0.872924\teval_dups-auc:0.947705\teval-auc:0.728202\n",
      "[500]\ttrain-auc:0.878899\teval_dups-auc:0.94779\teval-auc:0.72877\n",
      "[550]\ttrain-auc:0.88405\teval_dups-auc:0.947838\teval-auc:0.729227\n",
      "[600]\ttrain-auc:0.888887\teval_dups-auc:0.947615\teval-auc:0.729493\n",
      "[650]\ttrain-auc:0.893412\teval_dups-auc:0.947576\teval-auc:0.72953\n",
      "[700]\ttrain-auc:0.897847\teval_dups-auc:0.947638\teval-auc:0.73034\n",
      "[750]\ttrain-auc:0.90236\teval_dups-auc:0.947636\teval-auc:0.730419\n",
      "[800]\ttrain-auc:0.906163\teval_dups-auc:0.947658\teval-auc:0.730793\n",
      "[850]\ttrain-auc:0.909743\teval_dups-auc:0.947501\teval-auc:0.731005\n",
      "[900]\ttrain-auc:0.913245\teval_dups-auc:0.947476\teval-auc:0.7308\n",
      "[950]\ttrain-auc:0.916474\teval_dups-auc:0.94749\teval-auc:0.73107\n",
      "[1000]\ttrain-auc:0.919556\teval_dups-auc:0.947463\teval-auc:0.73098\n",
      "[1050]\ttrain-auc:0.922276\teval_dups-auc:0.947421\teval-auc:0.730886\n",
      "[1100]\ttrain-auc:0.925089\teval_dups-auc:0.947378\teval-auc:0.730739\n",
      "[1150]\ttrain-auc:0.927522\teval_dups-auc:0.947351\teval-auc:0.730489\n",
      "[1200]\ttrain-auc:0.930356\teval_dups-auc:0.947364\teval-auc:0.730508\n",
      "[1250]\ttrain-auc:0.9323\teval_dups-auc:0.947389\teval-auc:0.730773\n",
      "[1300]\ttrain-auc:0.934755\teval_dups-auc:0.947383\teval-auc:0.730933\n",
      "[1350]\ttrain-auc:0.936945\teval_dups-auc:0.947346\teval-auc:0.730693\n",
      "[1400]\ttrain-auc:0.938886\teval_dups-auc:0.947339\teval-auc:0.73078\n",
      "[1450]\ttrain-auc:0.940629\teval_dups-auc:0.947342\teval-auc:0.730771\n",
      "Stopping. Best iteration:\n",
      "[981]\ttrain-auc:0.91844\teval_dups-auc:0.947471\teval-auc:0.731136\n",
      "\n",
      "[0]\ttrain-auc:0.744099\teval_dups-auc:0.936788\teval-auc:0.68455\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.80229\teval_dups-auc:0.940474\teval-auc:0.706575\n",
      "[100]\ttrain-auc:0.814698\teval_dups-auc:0.941025\teval-auc:0.710002\n",
      "[150]\ttrain-auc:0.827791\teval_dups-auc:0.941603\teval-auc:0.714402\n",
      "[200]\ttrain-auc:0.837507\teval_dups-auc:0.941706\teval-auc:0.714436\n",
      "[250]\ttrain-auc:0.847304\teval_dups-auc:0.941782\teval-auc:0.715696\n",
      "[300]\ttrain-auc:0.856801\teval_dups-auc:0.941918\teval-auc:0.717049\n",
      "[350]\ttrain-auc:0.865397\teval_dups-auc:0.942161\teval-auc:0.718145\n",
      "[400]\ttrain-auc:0.872932\teval_dups-auc:0.942294\teval-auc:0.718614\n",
      "[450]\ttrain-auc:0.879904\teval_dups-auc:0.942308\teval-auc:0.71843\n",
      "[500]\ttrain-auc:0.886535\teval_dups-auc:0.942331\teval-auc:0.718584\n",
      "[550]\ttrain-auc:0.892008\teval_dups-auc:0.942336\teval-auc:0.718289\n",
      "[600]\ttrain-auc:0.896489\teval_dups-auc:0.942373\teval-auc:0.718338\n",
      "[650]\ttrain-auc:0.901038\teval_dups-auc:0.942402\teval-auc:0.718193\n",
      "[700]\ttrain-auc:0.904994\teval_dups-auc:0.942426\teval-auc:0.718387\n",
      "[750]\ttrain-auc:0.908908\teval_dups-auc:0.942442\teval-auc:0.718456\n",
      "[800]\ttrain-auc:0.912379\teval_dups-auc:0.942517\teval-auc:0.718897\n",
      "[850]\ttrain-auc:0.915709\teval_dups-auc:0.942482\teval-auc:0.718603\n",
      "[900]\ttrain-auc:0.918785\teval_dups-auc:0.942502\teval-auc:0.718746\n",
      "[950]\ttrain-auc:0.921753\teval_dups-auc:0.942525\teval-auc:0.718842\n",
      "[1000]\ttrain-auc:0.924377\teval_dups-auc:0.9425\teval-auc:0.718568\n",
      "[1050]\ttrain-auc:0.927056\teval_dups-auc:0.942514\teval-auc:0.718664\n",
      "[1100]\ttrain-auc:0.92956\teval_dups-auc:0.942512\teval-auc:0.718787\n",
      "[1150]\ttrain-auc:0.931643\teval_dups-auc:0.942528\teval-auc:0.718917\n",
      "[1200]\ttrain-auc:0.933958\teval_dups-auc:0.942556\teval-auc:0.719132\n",
      "[1250]\ttrain-auc:0.936098\teval_dups-auc:0.942625\teval-auc:0.719441\n",
      "[1300]\ttrain-auc:0.938229\teval_dups-auc:0.942514\teval-auc:0.719318\n",
      "[1350]\ttrain-auc:0.94018\teval_dups-auc:0.942537\teval-auc:0.719476\n",
      "[1400]\ttrain-auc:0.941861\teval_dups-auc:0.942544\teval-auc:0.719631\n",
      "[1450]\ttrain-auc:0.943459\teval_dups-auc:0.942552\teval-auc:0.71973\n",
      "[1500]\ttrain-auc:0.945299\teval_dups-auc:0.942519\teval-auc:0.719786\n",
      "[1550]\ttrain-auc:0.94677\teval_dups-auc:0.942548\teval-auc:0.720084\n",
      "[1600]\ttrain-auc:0.948356\teval_dups-auc:0.942546\teval-auc:0.720243\n",
      "[1650]\ttrain-auc:0.949787\teval_dups-auc:0.942546\teval-auc:0.720197\n",
      "[1700]\ttrain-auc:0.951106\teval_dups-auc:0.942455\teval-auc:0.720183\n",
      "[1750]\ttrain-auc:0.952609\teval_dups-auc:0.942448\teval-auc:0.720171\n",
      "[1800]\ttrain-auc:0.953991\teval_dups-auc:0.942424\teval-auc:0.720151\n",
      "[1850]\ttrain-auc:0.955251\teval_dups-auc:0.942445\teval-auc:0.720483\n",
      "[1900]\ttrain-auc:0.956521\teval_dups-auc:0.94237\teval-auc:0.720226\n",
      "[1950]\ttrain-auc:0.957715\teval_dups-auc:0.942379\teval-auc:0.72037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param = {'max_depth':10, 'eta':0.01, 'silent':1, 'objective':'binary:logistic' }\n",
    "#param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree']= 0.6\n",
    "param['min_child_weight'] = 1\n",
    "param['max_depth'] = 6\n",
    "param['booster'] = \"gbtree\"\n",
    "param['seed'] = 12345\n",
    "\n",
    "bst_d6 = {}\n",
    "#bst_linear = {} # optional\n",
    "\n",
    "for curfold in range(folds):\n",
    "#for curfold in [2]:\n",
    "    #watchlist  = [(dtrain[curfold],'train'), (dval_dups[curfold], 'eval_dups'), (dval[curfold], 'eval')]\n",
    "    watchlist  = [(dtrain[curfold],'train'), (dval_dups[curfold], 'eval_dups'), (dval[curfold], 'eval')]\n",
    "    num_round = 2000\n",
    "    early_stopping_rounds=500\n",
    "    bst_d6[curfold] = xgb.train(param, dtrain[curfold], num_round, watchlist,\n",
    "                       feval = feval_procleak,\n",
    "                       early_stopping_rounds=early_stopping_rounds, \n",
    "                       verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.624567\teval_dups-auc:0.916111\teval-auc:0.574633\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 500 rounds.\n",
      "[50]\ttrain-auc:0.763341\teval_dups-auc:0.936094\teval-auc:0.715502\n",
      "[100]\ttrain-auc:0.771242\teval_dups-auc:0.9368\teval-auc:0.719805\n",
      "[150]\ttrain-auc:0.778353\teval_dups-auc:0.937369\teval-auc:0.723115\n",
      "[200]\ttrain-auc:0.785659\teval_dups-auc:0.937785\teval-auc:0.725018\n",
      "[250]\ttrain-auc:0.793319\teval_dups-auc:0.9382\teval-auc:0.72675\n",
      "[300]\ttrain-auc:0.799847\teval_dups-auc:0.938669\teval-auc:0.728383\n",
      "[350]\ttrain-auc:0.805494\teval_dups-auc:0.938929\teval-auc:0.729526\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-276c54af083a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m                        \u001b[0mfeval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval_procleak\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                        \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                        verbose_eval=50)\n\u001b[0m",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/xgboost-0.4-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/xgboost-0.4-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/xgboost-0.4-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "param = {'max_depth':10, 'eta':0.01, 'silent':1, 'objective':'binary:logistic' }\n",
    "#param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree']= 0.6\n",
    "param['min_child_weight'] = 1\n",
    "param['max_depth'] = 5\n",
    "param['booster'] = \"gbtree\"\n",
    "param['seed'] = 12345\n",
    "\n",
    "bst_d5 = {}\n",
    "#bst_linear = {} # optional\n",
    "\n",
    "for curfold in range(folds):\n",
    "#for curfold in [2]:\n",
    "    #watchlist  = [(dtrain[curfold],'train'), (dval_dups[curfold], 'eval_dups'), (dval[curfold], 'eval')]\n",
    "    watchlist  = [(dtrain[curfold],'train'), (dval_dups[curfold], 'eval_dups'), (dval[curfold], 'eval')]\n",
    "    num_round = 2000\n",
    "    early_stopping_rounds=500\n",
    "    bst_d5[curfold] = xgb.train(param, dtrain[curfold], num_round, watchlist,\n",
    "                       feval = feval_procleak,\n",
    "                       early_stopping_rounds=early_stopping_rounds, \n",
    "                       verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_iteration': '1256', 'best_score': '0.745132', 'best_msg': '[1256]\\ttrain-auc:0.894881\\teval_dups-auc:0.941498\\teval-auc:0.745132'}\n",
      "{'best_iteration': '1999', 'best_score': '0.753396', 'best_msg': '[1999]\\ttrain-auc:0.921602\\teval_dups-auc:0.947338\\teval-auc:0.753396'}\n",
      "{'best_iteration': '811', 'best_score': '0.73237', 'best_msg': '[811]\\ttrain-auc:0.865569\\teval_dups-auc:0.948136\\teval-auc:0.73237'}\n",
      "{'best_iteration': '1043', 'best_score': '0.719873', 'best_msg': '[1043]\\ttrain-auc:0.887005\\teval_dups-auc:0.942731\\teval-auc:0.719873'}\n",
      "0 0.739538654098 0.941498369384\n",
      "1 0.737301126407 0.947338234202\n",
      "2 0.742346539954 0.948136152364\n",
      "3 0.739452499588 0.942730770974\n",
      "0.738588420596 0.944967708879\n"
     ]
    }
   ],
   "source": [
    "#m1\n",
    "preds_d5, df_preds_d5 = build_dfpreds_xgb(bst_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_msg': '[746]\\ttrain-auc:0.858042\\teval_dups-auc:0.941484\\teval-auc:0.746186', 'best_iteration': '746', 'best_score': '0.746186'}\n",
      "{'best_msg': '[239]\\ttrain-auc:0.805788\\teval_dups-auc:0.947217\\teval-auc:0.752327', 'best_iteration': '239', 'best_score': '0.752327'}\n",
      "{'best_msg': '[3]\\ttrain-auc:0.775678\\teval_dups-auc:0.948996\\teval-auc:0.740552', 'best_iteration': '3', 'best_score': '0.740552'}\n",
      "{'best_msg': '[479]\\ttrain-auc:0.831583\\teval_dups-auc:0.944428\\teval-auc:0.736211', 'best_iteration': '479', 'best_score': '0.736211'}\n",
      "0 0.753149331827 0.941484422522\n",
      "1 0.752985442728 0.947216783493\n",
      "2 0.758381677143 0.948996381774\n",
      "3 0.75686377369 0.944428114792\n",
      "0.728084245327 0.942640812557\n"
     ]
    }
   ],
   "source": [
    "#m2\n",
    "preds_d5, df_preds_d5 = build_dfpreds_xgb(bst_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_iteration': '1651', 'best_score': '0.746809', 'best_msg': '[1651]\\ttrain-auc:0.948672\\teval_dups-auc:0.941312\\teval-auc:0.746809'}\n",
      "{'best_iteration': '1679', 'best_score': '0.757333', 'best_msg': '[1679]\\ttrain-auc:0.948609\\teval_dups-auc:0.947664\\teval-auc:0.757333'}\n",
      "{'best_iteration': '981', 'best_score': '0.731136', 'best_msg': '[981]\\ttrain-auc:0.91844\\teval_dups-auc:0.947471\\teval-auc:0.731136'}\n",
      "{'best_iteration': '1999', 'best_score': '0.720694', 'best_msg': '[1999]\\ttrain-auc:0.958877\\teval_dups-auc:0.94241\\teval-auc:0.720694'}\n",
      "0 0.738310041721 0.941312147355\n",
      "1 0.738740267928 0.947664493458\n",
      "2 0.738601366685 0.947470504149\n",
      "3 0.733135302538 0.942410227846\n",
      "0.736510286003 0.944720903886\n"
     ]
    }
   ],
   "source": [
    "preds_d6, df_preds_d6 = build_dfpreds_xgb(bst_d6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preds_d5.to_pickle('predscv-7m4r2-d5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_iteration': '1384', 'best_msg': '[1384]\\ttrain-auc:0.878529\\teval_dups-auc:0.938891\\teval-auc:0.73028', 'best_score': '0.73028'}\n",
      "{'best_iteration': '1718', 'best_msg': '[1718]\\ttrain-auc:0.890728\\teval_dups-auc:0.946822\\teval-auc:0.747487', 'best_score': '0.747487'}\n",
      "{'best_iteration': '1654', 'best_msg': '[1654]\\ttrain-auc:0.887692\\teval_dups-auc:0.947503\\teval-auc:0.730663', 'best_score': '0.730663'}\n",
      "{'best_iteration': '1091', 'best_msg': '[1091]\\ttrain-auc:0.864189\\teval_dups-auc:0.942432\\teval-auc:0.721049', 'best_score': '0.721049'}\n",
      "0 0.622079375672 0.938890647326\n",
      "1 0.628981694176 0.946821876618\n",
      "2 0.599805157372 0.947502742127\n",
      "3 0.60200131103 0.942431994643\n",
      "0.612522320556 0.943952068017\n"
     ]
    }
   ],
   "source": [
    "# xgb7\n",
    "#preds_d5, df_preds_d5 = build_dfpreds_xgb(bst_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_iteration': '338', 'best_msg': '[338]\\ttrain-auc:0.723899\\teval_dups-auc:0.706475\\teval-auc:0.679699', 'best_score': '0.679699'}\n",
      "{'best_iteration': '999', 'best_msg': '[999]\\ttrain-auc:0.730359\\teval_dups-auc:0.712608\\teval-auc:0.68424', 'best_score': '0.68424'}\n",
      "{'best_iteration': '503', 'best_msg': '[503]\\ttrain-auc:0.723356\\teval_dups-auc:0.729673\\teval-auc:0.670418', 'best_score': '0.670418'}\n",
      "{'best_iteration': '999', 'best_msg': '[999]\\ttrain-auc:0.72717\\teval_dups-auc:0.724861\\teval-auc:0.671322', 'best_score': '0.671322'}\n",
      "0 0.709370912512 0.93198077234\n",
      "1 0.71259843731 0.937867897659\n",
      "2 0.730689823242 0.940478300383\n",
      "3 0.72486271743 0.934388239106\n",
      "0.719427019502 0.936269345713\n"
     ]
    }
   ],
   "source": [
    "#preds_lin, df_preds_lin = build_dfpreds_xgb(bstlin, ldval_dups, cv_val_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open('xgbl7f-output.pkl.gz', 'rb') as fd:\n",
    "    d_linpreds = pickle.load(fd)\n",
    "\n",
    "preds_lin = d_linpreds['train']\n",
    "df_preds_lin = d_linpreds['train_df']\n",
    "preds_lin_test = d_linpreds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_preds(dfs, clf):\n",
    "    \n",
    "    tgt = dfs[0][dfs[0].leak_fillmask].outcome.values.copy()\n",
    "    \n",
    "    preds = []\n",
    "    for df in dfs:\n",
    "        preds.append(df[df.leak_fillmask].pred_outcomel.values.copy())\n",
    "        \n",
    "    print(roc_auc_score(tgt, preds[0]))\n",
    "        \n",
    "    #preds.append(np.ones_like(preds[-1]))\n",
    "        \n",
    "    X = np.vstack(preds).T\n",
    "\n",
    "#    clf = sklearn.linear_model.Ridge()\n",
    "    clf.fit(X, tgt)\n",
    "    \n",
    "    merged = clf.predict(X)\n",
    "    merged = np.clip(merged, .001, .999)\n",
    "    \n",
    "    print(roc_auc_score(tgt, merged))\n",
    "\n",
    "    df_merged = dfs[0][['activity_id', 'outcome', 'pred_outcome', 'pred_outcomel', 'leak_fillmask']]\n",
    "    df_merged.pred_outcomel.values[np.where(dfs[0].leak_fillmask.values)] = merged\n",
    "    df_merged.pred_outcome.values[np.where(dfs[0].leak_fillmask.values)] = merged\n",
    "    \n",
    "    print(roc_auc_score(dfs[0].outcome.values, df_merged.pred_outcomel))\n",
    "\n",
    "    return df_merged, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74955264133\n",
      "0.75002324412\n",
      "0.94643684052\n"
     ]
    }
   ],
   "source": [
    "df_mergedout, clf = merge_preds([df_preds_d5, df_preds_d6], sklearn.linear_model.Ridge())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mergedout = df_preds_d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970475042392 0.990426490824\n",
      "0.974420841262 0.993112858563\n"
     ]
    }
   ],
   "source": [
    "tm = pd.merge(train, df_mergedout, on='activity_id', how='left').copy()\n",
    "\n",
    "#print(tm.pred_outcome.isnull().sum(), tm.pred_outcomel.isnull().sum())\n",
    "\n",
    "tm.loc[tm.pred_outcome.isnull(), ['pred_outcome']] = tm[tm.pred_outcome.isnull()]['outcome_filled_nona']\n",
    "tm.loc[tm.pred_outcomel.isnull(), ['pred_outcomel']] = tm[tm.pred_outcomel.isnull()]['outcome_filled_nona']\n",
    "\n",
    "print(sklearn.metrics.roc_auc_score(tm.outcome_x.values, tm.pred_outcome.values), \\\n",
    "sklearn.metrics.roc_auc_score(tm.outcome_x.values, tm.pred_outcomel.values))\n",
    "\n",
    "mask0 = np.full(len(tm), False, dtype=np.bool)\n",
    "for g in dreduct['grouplist_all0']:\n",
    "    mask0 = np.logical_or(mask0, tm.group_1 == g)\n",
    "\n",
    "mask1 = np.full(len(tm), False, dtype=np.bool)\n",
    "for g in dreduct['grouplist_all1']:\n",
    "    mask1 = np.logical_or(mask1, tm.group_1 == g)\n",
    "\n",
    "vals = (0, 1) # These groups are always 0/1 in test\n",
    "tm.pred_outcome.values[np.where(mask0)] = vals[0]\n",
    "tm.pred_outcomel.values[np.where(mask0)] = vals[0]\n",
    "\n",
    "tm.pred_outcome.values[np.where(mask1)] = vals[1]\n",
    "tm.pred_outcomel.values[np.where(mask1)] = vals[1]\n",
    "\n",
    "print(sklearn.metrics.roc_auc_score(tm.outcome_x.values, tm.pred_outcome.values), \\\n",
    "sklearn.metrics.roc_auc_score(tm.outcome_x.values, tm.pred_outcomel.values))\n",
    "\n",
    "#0.946852648526 0.989813329397\n",
    "#0.954428644246 0.992619147622 - w/ adate10_r .001 quant .992885\n",
    "\n",
    "#0.949455564305 0.989835569724\n",
    "#0.956555615812 0.992636323141 - first FE attempt .992881\n",
    "\n",
    "#0.955060286488 0.989917327586\n",
    "#0.96143899082 0.99269895942 - second FE attempt\n",
    "\n",
    "#0.967763129886 0.990062140532\n",
    "#0.972240541802 0.992828869816 - 7m1 d5\n",
    "#0.967298424983 0.989985499522\n",
    "#0.971925205949 0.992778873978 - d6 (so d5 might be better)\n",
    "\n",
    "#0.97000016041 0.990225258698\n",
    "#0.974089176638 0.992948181038 - 7m2 d5\n",
    "\n",
    "#0.969949811863 0.990401393144\n",
    "#0.973875698791 0.993074997241 - 7m3 d5\n",
    "\n",
    "#0.970564734627 0.990424342822\n",
    "#0.974527494216 0.993108191472 - 7m4 d5\n",
    "\n",
    "#0.970475042392 0.990426490824\n",
    "#0.974420841262 0.993112858563 - 7m4r d5+d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mat_test = buildmatrix(test, False)\n",
    "#dtest = xgb.DMatrix(mat_test, missing=np.nan)\n",
    "\n",
    "#lmat_test = buildmatrix(test, linear=True)\n",
    "#ldtest = xgb.DMatrix(lmat_test, missing=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xgbmdl_to_test(mdl, dmat = dtest):\n",
    "    output = np.zeros(len(test), dtype=np.float64)\n",
    "    for f in range(folds):\n",
    "        try:\n",
    "            output += mdl[f].predict(dmat, ntree_limit=mdl[f].best_ntree_limit)\n",
    "        except: # Linear model\n",
    "            o = mdl[f].predict(dmat)\n",
    "            o = o.clip(.001, .999)\n",
    "            output += o\n",
    "            \n",
    "    return output / folds\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "#[df_preds_d4, df_preds_d5, df_preds_d6, df_preds_d7, df_preds_d8, df_preds_d9, df_preds_lin]\n",
    "#outputs.append(xgbmdl_to_test(bst_d4))\n",
    "outputs.append(xgbmdl_to_test(bst_d5))\n",
    "outputs.append(xgbmdl_to_test(bst_d6))\n",
    "#outputs.append(xgbmdl_to_test(bst_d7))\n",
    "#outputs.append(xgbmdl_to_test(bst_d8))\n",
    "#outputs.append(xgbmdl_to_test(bst_d9))\n",
    "#outputs.append(preds_lin_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0097536049618 0.922685520993\n"
     ]
    }
   ],
   "source": [
    "if len(outputs) > 1:\n",
    "    moutputs = np.vstack(outputs).T\n",
    "\n",
    "    outputa = clf.predict(moutputs)\n",
    "\n",
    "    print(np.min(outputa), np.max(outputa))\n",
    "    outputa = np.clip(outputa, .001, .999)\n",
    "else:\n",
    "    outputa = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = test.outcome_filled.values.copy()\n",
    "\n",
    "mask = np.where(output != output)\n",
    "output[np.where(output != output)] = outputa[mask]\n",
    "\n",
    "test_out =  test[['activity_id']].copy()\n",
    "test_out['outcome'] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_out.to_csv('Submission-7m4r-d5-d6-usethis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96762736900893409"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = test.outcome_filled.values.copy()\n",
    "\n",
    "imask = output == 1.0\n",
    "imask = np.logical_or(imask, output == 0.0)\n",
    "\n",
    "test_tgt = output[np.where(imask)]\n",
    "test_preds = outputa[np.where(imask)]\n",
    "\n",
    "#test_tgt[test_tgt < .5] = 0\n",
    "#test_tgt[test_tgt >= .5] = 1\n",
    "\n",
    "roc_auc_score(test_tgt, test_preds) #0.84179900687486708\n",
    "#0.74025122141974342 .992881\n",
    "#0.96740052157355261 - m1\n",
    "#0.96176368357003805 - m2\n",
    "#0.9693393882776864 - m3\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
